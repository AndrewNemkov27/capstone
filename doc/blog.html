<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andrew Nemkov">

<title>Grappler Baki Word Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="blog_files/libs/clipboard/clipboard.min.js"></script>
<script src="blog_files/libs/quarto-html/quarto.js"></script>
<script src="blog_files/libs/quarto-html/popper.min.js"></script>
<script src="blog_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="blog_files/libs/quarto-html/anchor.min.js"></script>
<link href="blog_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="blog_files/libs/quarto-html/quarto-syntax-highlighting-29e2c20b02301cfff04dc8050bf30c7e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="blog_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="blog_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="blog_files/libs/bootstrap/bootstrap-933a14f46f0e4d1503cecf416b5e09b4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#motivation-background" id="toc-motivation-background" class="nav-link active" data-scroll-target="#motivation-background">Motivation &amp; Background</a></li>
  <li><a href="#dataset-foundation" id="toc-dataset-foundation" class="nav-link" data-scroll-target="#dataset-foundation">Dataset Foundation</a>
  <ul class="collapse">
  <li><a href="#dataset-creation" id="toc-dataset-creation" class="nav-link" data-scroll-target="#dataset-creation">Dataset Creation</a></li>
  </ul></li>
  <li><a href="#example-extraction" id="toc-example-extraction" class="nav-link" data-scroll-target="#example-extraction">Example Extraction</a></li>
  <li><a href="#dataset-preprocessing" id="toc-dataset-preprocessing" class="nav-link" data-scroll-target="#dataset-preprocessing">Dataset Preprocessing</a></li>
  <li><a href="#ocr-confidence-and-word-complexity" id="toc-ocr-confidence-and-word-complexity" class="nav-link" data-scroll-target="#ocr-confidence-and-word-complexity">OCR Confidence and Word Complexity</a>
  <ul class="collapse">
  <li><a href="#word-length-trends" id="toc-word-length-trends" class="nav-link" data-scroll-target="#word-length-trends">Word Length Trends</a></li>
  <li><a href="#ocr-confidence-by-character-type" id="toc-ocr-confidence-by-character-type" class="nav-link" data-scroll-target="#ocr-confidence-by-character-type">OCR Confidence by Character Type</a></li>
  <li><a href="#combined-insights" id="toc-combined-insights" class="nav-link" data-scroll-target="#combined-insights">Combined Insights</a></li>
  </ul></li>
  <li><a href="#language-characteristics-and-story-telling" id="toc-language-characteristics-and-story-telling" class="nav-link" data-scroll-target="#language-characteristics-and-story-telling">Language Characteristics and Story Telling</a>
  <ul class="collapse">
  <li><a href="#word-frequency-snapshot" id="toc-word-frequency-snapshot" class="nav-link" data-scroll-target="#word-frequency-snapshot">Word Frequency Snapshot</a></li>
  <li><a href="#parts-of-speech-distribution" id="toc-parts-of-speech-distribution" class="nav-link" data-scroll-target="#parts-of-speech-distribution">Parts of Speech Distribution</a></li>
  <li><a href="#tf-idf-insights" id="toc-tf-idf-insights" class="nav-link" data-scroll-target="#tf-idf-insights">TF-IDF Insights</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Grappler Baki Word Analysis</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">A Data Science Approach to Understanding Language in Baki</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Andrew Nemkov </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="blog_assets/p2Blog.png" class="img-fluid figure-img" alt="One of numerous manga panels from the Baki manga."></p>
<figcaption>Manga Panel of Hanma Baki.</figcaption>
</figure>
</div>
<section id="motivation-background" class="level1">
<h1>Motivation &amp; Background</h1>
<p><strong>“強くあろうとする姿はかくも美しい”</strong></p>
<p>The short Japanese phrase above translates literally to “That who has a strong frame is beautiful”. In a more general sense, it conveys the idea that one’s body, once properly trained and developed, expresses more beauty than traditional features such as one’s face.</p>
<p>This often complicated and multi-layered idea is a foundational theme in the Japanese comic book style manga of <em>Grappler Baki</em>. In the story, a 17 year old boy by the name of Baki spends countless hours training and developing himself physically and mentally to one day stand in front of his father, the “strongest creature alive”, and challenge him in martial combat.</p>
<p><em>Grappler Baki</em> is an example of one of today’s few globally recognized Japanese works of visual and textual art that pushes the boundaries to what it means to be masculine. Popular as it is, the work’s origin creates a barrier for those outside of Japan to interact with the manga. As a result of this language gap, the need for this project was born.</p>
<p>Utilizing data science techniques, I aim to bridge this gap in linguistics by analyzing the words used withing Baki’s universe. Utilizing the tools of natural language processing, I seek to provide a deeper understanding of the work’s narrative structure and themes that define <em>Grappler Baki</em>.</p>
</section>
<section id="dataset-foundation" class="level1">
<h1>Dataset Foundation</h1>
<p>To undertake such a difficult task of bridging the gap between my English and the Japanese of Grappler Baki, I first needed to create a proper dataset that would contains all the written content used to describe Baki’s story over a large assortment of Japanese manga panels. For this, I discovered a site known as <a href="https://dl-raw.ac/">dl-raw.ac</a> that contained downloadable content on various Japanese manga, broken down by series. In this site, I downloaded pages for the three Baki series of my personal choice: Baki Rahen manga series (see <a href="https://dl-raw.ac/%e5%88%83%e7%89%99%e3%82%89%e3%81%b8%e3%82%93-raw/">Baki Rahen Page</a>), Baki Dou 2 manga series (see <a href="https://dl-raw.ac/%e5%88%83%e7%89%99%e9%81%93-%e7%ac%ac01-20%e5%b7%bb-baki-dou-vol-01-20/">Baki Dou 2 Page</a>), and Hanma Baki manga series (see <a href="https://dl-raw.ac/%e7%af%84%e9%a6%ac%e5%88%83%e7%89%99-hanma-baki/">Hanma Baki Page</a>). In total, the three downloads contained roughly 4000 Japanese manga pages describing various parts of Baki’s life as a fighter.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Validity of dl-raw.ac Website
</div>
</div>
<div class="callout-body-container callout-body">
<p>Some things to note about the website I utilized to get my data:</p>
<ol type="1">
<li>The site is publicly accessible.</li>
<li>The analysis of this project was performed for non-commercial purposes only.</li>
<li>All source citations were provided.</li>
<li>The data used in this project will not be redistributed.</li>
</ol>
</div>
</div>
<p>After gathering the source of my data, I needed a tool that I could use to extract the Japanese text from these images and turn the result into a computer-readable format. For this I utilized Optical Character Recognition (OCR), which would take in a Japanese manga image as input and output extracted Japanese phrases with each having a confidence score for how correctly the model thinks it extracted that portion of text.</p>
<p>For a detailed explanation on the process of using this machine learning, please see below:</p>
<ol type="1">
<li><a href="https://www.geeksforgeeks.org/what-is-optical-character-recognition-ocr/">GeekForGeeks site OCR explanation</a> and <a href="https://www.ibm.com/think/topics/optical-character-recognition">IBM site OCR explanation</a></li>
<li><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/main/README_en.md">Documentation of PaddleOCR</a></li>
<li><a href="https://www.youtube.com/watch?v=t5xwQguk9XU">Tutorial Video for PaddleOCR</a></li>
</ol>
<p><strong>Japanese Overview</strong></p>
<p>Further context is required to better understand the results of my project. In this part, I will explain the basic way that the Japanese writing system functions. In short, the Japanese language is written in a combination of three writing systems: hiragana, katakana, and kanji. Hiragana and katakana are “kana” or system of Japanese alphabet, where one letter represents a sound. Hiragana is used for words originated from Japan, while katakana is used to represent foreign words adapted from outside Japan. On the other hand, kanji represent logographic characters, or ones where a letter represents a concept or idea instead of a sound. For this reason, kanji are more complicated that hiragana and katakana. This basic information will be crucial to understand several of my project’s variables.</p>
<section id="dataset-creation" class="level2">
<h2 class="anchored" data-anchor-id="dataset-creation">Dataset Creation</h2>
<p><strong>Setup</strong></p>
<p>To begin an exaplanation of the OCR code used in this project, it is essential to start with the correct python libraries. Almost all were utilized in the data preparation process. Specifically, I used the <strong>cv2</strong> python library for file reading and image preprocessing, the <strong>re</strong> python library for cleaning of words, csv to read my extraction into a dataset, <strong>os</strong> for file path creation, the <strong>gc</strong> python library for cleaning memory, the <strong>fugashi</strong> python library to separate phrases into words, the <strong>Counter</strong> python library to count word frequency, the <strong>PaddleOCR</strong> python library to import the proper OCR model, and the <strong>Translator</strong> python library to translate extracted Japanese words to English.</p>
<p>The data creation process continued with utilizing the above libraries to create a meaninful dataset for analysis. I used figashi to tokenize words as well as identify each word’s part of speech and in addition to this, those words that were not identified into groups were set as “unknown”. I continued by translating my Japanese words into English using Google translate as well as calculating the Japanese ratios of types of characters in each word. Each word was given three ratios for the proportion of hiragana, katakana, and kanji characters in each word.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Further Data Creation Information
</div>
</div>
<div class="callout-body-container callout-body">
<p>Please note an important aspect of the way that more extractions are added to the dataset. Column names are written so that if they currently exist in the dataset, then new ones will not be added, but if a dataset has no headers then the provided will be added before all other information.</p>
<p>In addition, to limit performance issues of the Visual Studio Code application and OCR heavy processing requirement, I added a small amount of code to clean the memory of the process after an image is processed and added to the dataset.</p>
</div>
</div>
<p><strong>Parameter Tuning</strong></p>
<p>The parameters of the OCR model for this project are just as important as creating the columns of the dataset. Finding the right parameters to use took lots of experimentation, as I kept slightly adjusting the OCR’s rec_batch_num, det_db_box_thresh, det_db_unclip_ratio, rec_max_len, and drop_score. Below I explained these parameters further below:</p>
<ol type="1">
<li>The rec_batch_num represents the model’s batch size processing parameter that when increased, increases the speed of the machine learning’s processing.</li>
<li>The det_db_box_thresh parameter represents the box detection confidence, which when increased changes the model to only detect more clearer text boxes.</li>
<li>On the other hand, det_db_unclip_ratio when increased makes the model detect more words or symbols.</li>
<li>The rec_max_len parameter is easier to understand, as this simply limits the total length of an extracted phrase.</li>
<li>The final parameter of drop_score limits the maximum score that the OCR model can process and add the dataset, as all phrases extracted with a lower score than the threshold will be discarded.</li>
</ol>
<p><strong>Features</strong></p>
<p>For final clarity of the visualizations and results of the project, below are simple explanations of all the features of the dataset:</p>
<ol type="1">
<li><strong>word_JAP</strong>: Japanese word from extracted Japanese phrase.</li>
<li><strong>word_US</strong>: English word translated from word_JAP.</li>
<li><strong>word_POS</strong>: Part of speech for word_JAP.</li>
<li><strong>phrase_JAP</strong>: Japanese phrase extracted from Baki manga JPG image.</li>
<li><strong>img_title</strong>: Title of Baki manga JPG image.</li>
<li><strong>img_series</strong>: Manga series of Baki manga JPG image.</li>
<li><strong>length</strong>: Length of word_JAP.</li>
<li><strong>confidence</strong>: OCR confidence score of extracted Japanese phrase.</li>
<li><strong>word_freq</strong>: Decimal value of how often a particular Japanese word appears in dataset (calculated separately from other data creation steps for simplicity)</li>
<li><strong>hiragana_ratio</strong>: Ratio of hiragana characters in word_JAP.</li>
<li><strong>katakana_ratio</strong>: Ratio of katakana characters in word_JAP.</li>
<li><strong>kanji_ratio</strong>: Ratio of kanji characters in word_JAP.</li>
</ol>
</section>
</section>
<section id="example-extraction" class="level1">
<h1>Example Extraction</h1>
<p>Below is a short demonstration of the process of the PaddleOCR model I utilized in my project. The machine learning model is given an image to analyze, it identifies and extracts Japanese text, proper cleaning and calculations are performed with these extracted phrases, and the result is recorded in the dataset.</p>
<p><strong>Step 1: Obtain Image</strong></p>
<p>Below is an example of one of 4000 Japanese manga panels from the Grappler Baki manga. In this specific case, the image comes at the end of a chapter, which is why the right half is black while the left shows drawings and text.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="blog_assets/Implementation1.png" class="img-fluid figure-img" alt="Image showing PaddleOCR identifying text in DL-Raw.Net_48 (2).jpg image."></p>
<figcaption>Example Japanese manga panel named DL-Raw.Net_48 (2).jpg.</figcaption>
</figure>
</div>
<p>The process begins with an image input. In this example, I used a image with few words for simplicity titled DL-Raw.Net_48 (2).jpg. The OCR model runs its machine learning algorithm and identifies the Japanese text seen in the bright red box above.</p>
<p><strong>Step 2: Extract Text</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="blog_assets/Implementation2.png" class="img-fluid figure-img" alt="Image showing test run of PaddleOCR code on image named DL-Raw.Net_48 (2).jpg."></p>
<figcaption>Test image python OCR output.</figcaption>
</figure>
</div>
<p>The model takes the identified text and formats it into a computer readable format. After this, the OCR continues to attempt to identify any more text phrases, following the repreating process of identification and transformation in format until no more text can be identified on the image. When this occurs, a numered success message is given in the output, showing the ending of OCR process on the DL-Raw.Net_48 (2).jpg image.</p>
<p><strong>Step 3: Add to Dataset</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="blog_assets/Implementation3.png" class="img-fluid figure-img" alt="Image showing extracted information and calculated features obtained by running PaddleOCR on image named DL-Raw.Net_48 (2).jpg."></p>
<figcaption>Test image dataset implementation.</figcaption>
</figure>
</div>
<p>The identified information of the example image is the actual extracted phrase and the model’s confidence of this extraction. These two key pieces are input into a dataset. Following this, my own code performs several steps of further calculations from both the information about the image and the Japanese text that was extracted.</p>
<p>The result of my calculations and further data preparation is seen above with a small dataset including headers, the extraced Japanese phrase of 他の監, and two words of 他 and 監 which were obtained from this phrase from the above example image. It is important to note that the symbol の is read as “no” and serves a grammatical phrase of the role, explaining why there are two words and not three in the example dataset.</p>
</section>
<section id="dataset-preprocessing" class="level1">
<h1>Dataset Preprocessing</h1>
<div id="cell-First-5-Rows" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gaussian_kde</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> LinearSegmentedColormap</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> mpatches</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.colors <span class="im">as</span> mcolors</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> NMF</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset name</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>csv_file <span class="op">=</span> <span class="vs">r"C:\Users\andne\OneDrive\Pictures\Capstone1\capstone\(1)-main\(1)-codeAndData\realData.csv"</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># make dataframe of data</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(csv_file)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># remove outliers (words longer than 10 characters)</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>df_filtered <span class="op">=</span> df[df[<span class="st">"length"</span>] <span class="op">&lt;=</span> <span class="dv">10</span>].copy()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>display(df_filtered.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="first-5-rows" class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">word_JAP</th>
<th data-quarto-table-cell-role="th">word_US</th>
<th data-quarto-table-cell-role="th">word_POS</th>
<th data-quarto-table-cell-role="th">phrase_JAP</th>
<th data-quarto-table-cell-role="th">img_title</th>
<th data-quarto-table-cell-role="th">img_series</th>
<th data-quarto-table-cell-role="th">length</th>
<th data-quarto-table-cell-role="th">confidence</th>
<th data-quarto-table-cell-role="th">word_freq</th>
<th data-quarto-table-cell-role="th">hiragana_ratio</th>
<th data-quarto-table-cell-role="th">katakana_ratio</th>
<th data-quarto-table-cell-role="th">kanji_ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>新装</td>
<td>Newly available</td>
<td>noun</td>
<td>新装板</td>
<td>DL-Raw.Net_1 (2).jpg</td>
<td>Hanma_Baki</td>
<td>2</td>
<td>0.65</td>
<td>0.0006</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>板</td>
<td>Board</td>
<td>unknown</td>
<td>新装板</td>
<td>DL-Raw.Net_1 (2).jpg</td>
<td>Hanma_Baki</td>
<td>1</td>
<td>0.65</td>
<td>0.0014</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>板垣</td>
<td>Itagaki</td>
<td>noun</td>
<td>板垣恵介</td>
<td>DL-Raw.Net_1 (2).jpg</td>
<td>Hanma_Baki</td>
<td>2</td>
<td>0.96</td>
<td>0.0043</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>恵介</td>
<td>Keisuke</td>
<td>noun</td>
<td>板垣恵介</td>
<td>DL-Raw.Net_1 (2).jpg</td>
<td>Hanma_Baki</td>
<td>2</td>
<td>0.96</td>
<td>0.0045</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>新装</td>
<td>Newly available</td>
<td>noun</td>
<td>新装板</td>
<td>DL-Raw.Net_1.jpg</td>
<td>Hanma_Baki</td>
<td>2</td>
<td>0.88</td>
<td>0.0006</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
<p>Figure 0.5: First five rows of dataset.</p>
</div>
</div>
<p>After successfully choosing an OCR model, performing the necessary setup, and adjusting the model’s parameters, I began my word analysis by importing the necessary python libraries.</p>
<p>Some important ones I mentioned below:</p>
<ol type="1">
<li>I calculate jittering in scatter plot points using the the <strong>gaussian_kde</strong> library.</li>
<li>I perform a TF-IDf analysis to obtain importance of words in a dataset using the <strong>TfidfVectorizer</strong> library.</li>
<li>I perform NMF analysis to group words into distinct themes using the <strong>NMF</strong> library.</li>
</ol>
<p>In addition to the standard method of reading in a CSV dataset, I also filtered the data to exclude words longer than 10 characters, as this was clearly an tokenization error. This means some words were not correctly split from their parent phrases and therefore proper word analysis can’t be performed on them. As a result, I cleaned the data to include only single word entries for the main word_JAP column.</p>
</section>
<section id="ocr-confidence-and-word-complexity" class="level1">
<h1>OCR Confidence and Word Complexity</h1>
<p>The first part of my analysis involved researching the correlations between an OCR model’s confidence and an extracted word’s complexity. In this case complexity considers both the length of the extracted Japanese word as well as the types of Japanese characters that make up this word. Separate analysis of these two simpler relationships can yield significant understanding of what variables most notably decrease an OCR model’s confidence score for a extracted phrase, allowing for better future application of the project.</p>
<section id="word-length-trends" class="level2">
<h2 class="anchored" data-anchor-id="word-length-trends">Word Length Trends</h2>
<div id="cell-Q1-scatter" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filter words with more than 15 characters</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>long_words <span class="op">=</span> df[df[<span class="st">"word_JAP"</span>].<span class="bu">str</span>.<span class="bu">len</span>() <span class="op">&gt;</span> <span class="dv">15</span>][[<span class="st">"word_JAP"</span>, <span class="st">"word_US"</span>]]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print(long_words)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># jitter strength</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>jitter_strength <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># Adjust this value as needed</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># create jittered columns</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">"jittered_length"</span>] <span class="op">=</span> df_filtered[<span class="st">"length"</span>] <span class="op">+</span> np.random.uniform(<span class="op">-</span>jitter_strength, jitter_strength, <span class="bu">len</span>(df_filtered))</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">"jittered_confidence"</span>] <span class="op">=</span> df_filtered[<span class="st">"confidence"</span>] <span class="op">+</span> np.random.uniform(<span class="op">-</span>jitter_strength, jitter_strength, <span class="bu">len</span>(df_filtered))</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># KDE calculation using jittered values</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> np.vstack([df_filtered[<span class="st">'jittered_length'</span>], df_filtered[<span class="st">'jittered_confidence'</span>]])</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> gaussian_kde(xy)  </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>density <span class="op">=</span> kde(xy)  </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize density values</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>norm_density <span class="op">=</span> (density <span class="op">-</span> np.<span class="bu">min</span>(density)) <span class="op">/</span> (np.<span class="bu">max</span>(density) <span class="op">-</span> np.<span class="bu">min</span>(density))</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># custom red palette (light red to dark red)</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>custom_reds <span class="op">=</span> LinearSegmentedColormap.from_list(</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">"custom_reds"</span>, [<span class="st">"#ffa07a"</span>, <span class="st">"#f08080"</span>, <span class="st">"#ff0000"</span>, <span class="st">"#ce2029"</span>, <span class="st">"#8b0000"</span>]</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># question 1 plot 1: scatter plot with density-based coloring</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">6.5</span>, <span class="fl">4.5</span>))</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>df_filtered[<span class="st">"jittered_length"</span>], </span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>df_filtered[<span class="st">"jittered_confidence"</span>], </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span>norm_density,</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>custom_reds,  <span class="co"># Apply custom red gradient</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    edgecolor<span class="op">=</span><span class="va">None</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression line</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>sns.regplot(x<span class="op">=</span>df_filtered[<span class="st">"jittered_length"</span>], y<span class="op">=</span>df_filtered[<span class="st">"jittered_confidence"</span>], scatter<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">"red"</span>, line_kws<span class="op">=</span>{<span class="st">"linewidth"</span>: <span class="dv">2</span>})</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Set y-axis limit between 0.65 and 1</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.65</span>, <span class="dv">1</span>)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Word Length"</span>)</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"OCR Confidence"</span>)</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.title("Scatter Plot: OCR Confidence vs. Word Length (With Jitter &amp; Density Coloring)")</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>legend_labels <span class="op">=</span> [</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#8b0000"</span>, label<span class="op">=</span><span class="st">"Very High Density"</span>),</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#ce2029"</span>, label<span class="op">=</span><span class="st">"High Density"</span>),</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#ff0000"</span>, label<span class="op">=</span><span class="st">"Medium Density"</span>),</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#f08080"</span>, label<span class="op">=</span><span class="st">"Low Density"</span>),</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#ffa07a"</span>, label<span class="op">=</span><span class="st">"Very Low Density"</span>),</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_labels, title<span class="op">=</span><span class="st">"Density"</span>, loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="q1-scatter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="blog_files/figure-html/q1-scatter-output-1.png" width="560" height="398" class="figure-img"></p>
<figcaption>Figure 1.1: Scatter plot showing relationship between OCR confidence and word length.</figcaption>
</figure>
</div>
</div>
</div>
<p>Analysis of the relationship between OCR confidence and word complexity begins by understanding the relationship between confidence and word length. I originally speculated that longer words are inherently more complex, therefore it would be more difficult for the model to extract them.</p>
<p>To test this theory I wrote a scatter plot depicting the correlation between word length and OCR confidence. The original result was poorly visualized, so I implemented jittering of the scatterplot points for minimum variety of spacing, as well as added custom labels for five levels of density of points ranging from “Very High Density” to “Very Low Density”. These labels were used to color the points in the graph, with darker red representing higher density and lighter red representing lower density. One final addition to the graphic was the use of a line-of-best-fit to help point the relationship between the two variables.</p>
<p>The results of these adjustments are seen above in figure 1.1, where the features of word length and OCR confidence is positive (unlike my original guess of the relationship being negative). This means that as a Japanese word’s length increases, the chance of it being extracted with higher OCR confidence increases. This result may be explained by the nature of how Japanese words are written, as words written with more complicated characters tend to often be shorter than those written with simpler characters.</p>
</section>
<section id="ocr-confidence-by-character-type" class="level2">
<h2 class="anchored" data-anchor-id="ocr-confidence-by-character-type">OCR Confidence by Character Type</h2>
<div id="cell-Q1-box" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hide warnings for readability</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    warnings.simplefilter(<span class="st">"ignore"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># function to find dominant character type</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> classify_character_type(row):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        max_ratio <span class="op">=</span> <span class="bu">max</span>(row[<span class="st">"hiragana_ratio"</span>], row[<span class="st">"katakana_ratio"</span>], row[<span class="st">"kanji_ratio"</span>])</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_ratio <span class="op">==</span> row[<span class="st">"kanji_ratio"</span>]:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"Kanji"</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> max_ratio <span class="op">==</span> row[<span class="st">"katakana_ratio"</span>]:</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"Katakana"</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"Hiragana"</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># apply classification</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    df_filtered[<span class="st">"char_type"</span>] <span class="op">=</span> df_filtered.<span class="bu">apply</span>(classify_character_type, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># question 1 plot 2: box plot</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="fl">7.5</span>, <span class="fl">5.5</span>))</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">"char_type"</span>, </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">"confidence"</span>, </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        data<span class="op">=</span>df_filtered, </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        palette<span class="op">=</span><span class="st">"Reds"</span>,</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        whiskerprops<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">"black"</span>),  <span class="co"># whiskers</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        capprops<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">"black"</span>),  <span class="co"># caps</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        medianprops<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">"black"</span>)  <span class="co"># median line</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Dominant Character Type"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"OCR Confidence"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.title("Box Plot: OCR Confidence vs. Japanese Character Type")</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="q1-box" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="blog_files/figure-html/q1-box-output-1.png" width="635" height="466" class="figure-img"></p>
<figcaption>Figure 1.2: Box plot showing relationship between OCR confidence and Japanese writing systems.</figcaption>
</figure>
</div>
</div>
</div>
<p>The above visualization of figure 1.2 shows a box plot that shows the relationship between OCR confidence and the three types of Japanese writing systems. The graphics shows that model confidence for hiragana dominant Japanese words is higher than for katakana and kanji dominant Japanese words. This result explains that more complicated letters such as katakana and kanji are more difficult for the OCR model to process and extract compared to simpler hiragana letters.</p>
</section>
<section id="combined-insights" class="level2">
<h2 class="anchored" data-anchor-id="combined-insights">Combined Insights</h2>
<div id="cell-Q1-heat" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use only relevant numerical columns</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>correlation_data <span class="op">=</span> df_filtered[[<span class="st">"confidence"</span>, <span class="st">"length"</span>, <span class="st">"hiragana_ratio"</span>, <span class="st">"katakana_ratio"</span>, <span class="st">"kanji_ratio"</span>]]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation matrix</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> correlation_data.corr()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># question 1 plot 3: heatmap</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    corr_matrix, </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,  <span class="co"># show correlation values</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"Reds"</span>, </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">".2f"</span>,  <span class="co"># format numbers to 2 decimal places</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    linewidths<span class="op">=</span><span class="fl">0.5</span>,  <span class="co"># add lines between cells for clarity</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>  <span class="co"># ensure consistent color scaling</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># tilt x axis names</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">"right"</span>, rotation_mode<span class="op">=</span><span class="st">"anchor"</span>, x<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.title("Heatmap: Correlation of Word Characteristics")</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="q1-heat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="blog_files/figure-html/q1-heat-output-1.png" width="638" height="482" class="figure-img"></p>
<figcaption>Figure 1.3: Heatmap showing correlation of word characteristics.</figcaption>
</figure>
</div>
</div>
</div>
<p>The figure 1.3 above is a heatmap that summarizes the findings of the previous two visualizations (figure 1.1 and figure 1.2). It shows the relationships between the features of OCR confidence, word length, the ratio of hiragana in a Japanese word, the ratio of katakana in a Japanese word, and the ratio of kanji in a Japanese word. From the graph, it is clear that an OCR model’s confidence score correlates positively with word length and hiragana ratio in a word, meaning that as a word’s length increases and/or hiragana ratio increases, then the confidence by which it was extracted with also increases. On the other hand, an OCR model’s confidence score correlates negatively with katakana ratio and kanji ratio of Japanese words, meaning that as the katakana ratio and/or kanji ratio of characters in a Japanese word increases, then the confidence by which this word was extracted by the model decreases. This result explains that the OCR model poorly performs on words with complex letters rather than longer words.</p>
</section>
</section>
<section id="language-characteristics-and-story-telling" class="level1">
<h1>Language Characteristics and Story Telling</h1>
<p>To better understand the use of language in Grappler Baki, I continued my analysis on the grammatical and linguistic characteristics of words in the manga work. To simplify I performed analysis to see what information I can find regarding the frequency of used words, parts of speech, and in general the importance of word usage. This side of my project also delves more into understanding the themes present in <em>Grappler Baki</em>.</p>
<section id="word-frequency-snapshot" class="level2">
<h2 class="anchored" data-anchor-id="word-frequency-snapshot">Word Frequency Snapshot</h2>
<div id="cell-Q2-bar1" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># list of useless words to filter out</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>stopwords <span class="op">=</span> {</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"the"</span>, <span class="st">"a"</span>, <span class="st">"an"</span>, <span class="st">"and"</span>, <span class="st">"or"</span>, <span class="st">"but"</span>, <span class="st">"if"</span>, <span class="st">"so"</span>, <span class="st">"because"</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"in"</span>, <span class="st">"on"</span>, <span class="st">"at"</span>, <span class="st">"to"</span>, <span class="st">"from"</span>, <span class="st">"with"</span>, <span class="st">"by"</span>, <span class="st">"about"</span>, <span class="st">"of"</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"is"</span>, <span class="st">"are"</span>, <span class="st">"was"</span>, <span class="st">"were"</span>, <span class="st">"be"</span>, <span class="st">"being"</span>, <span class="st">"been"</span>, <span class="st">"am"</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"have"</span>, <span class="st">"has"</span>, <span class="st">"had"</span>, <span class="st">"do"</span>, <span class="st">"does"</span>, <span class="st">"did"</span>, <span class="st">"can"</span>, <span class="st">"could"</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"will"</span>, <span class="st">"would"</span>, <span class="st">"shall"</span>, <span class="st">"should"</span>, <span class="st">"must"</span>, <span class="st">"may"</span>, <span class="st">"might"</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"this"</span>, <span class="st">"that"</span>, <span class="st">"these"</span>, <span class="st">"those"</span>, <span class="st">"there"</span>, <span class="st">"here"</span>, <span class="st">"where"</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"when"</span>, <span class="st">"how"</span>, <span class="st">"say"</span>, <span class="st">"said"</span>, <span class="st">"tell"</span>, <span class="st">"told"</span>, <span class="st">"see"</span>, <span class="st">"saw"</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"look"</span>, <span class="st">"looked"</span>, <span class="st">"come"</span>, <span class="st">"go"</span>, <span class="st">"went"</span>, <span class="st">"take"</span>, <span class="st">"took"</span>,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"make"</span>, <span class="st">"made"</span>, <span class="st">"get"</span>, <span class="st">"got"</span>, <span class="st">"know"</span>, <span class="st">"knew"</span>, <span class="st">"think"</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"thought"</span>, <span class="st">"want"</span>, <span class="st">"wanted"</span>, <span class="st">"like"</span>, <span class="st">"liked"</span>, <span class="st">"need"</span>,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"needed"</span>, <span class="st">"use"</span>, <span class="st">"used"</span>, <span class="st">"find"</span>, <span class="st">"found"</span>, <span class="st">"give"</span>, <span class="st">"gave"</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"work"</span>, <span class="st">"works"</span>, <span class="st">"working"</span>, <span class="st">"try"</span>, <span class="st">"tried"</span>, <span class="st">"ask"</span>, <span class="st">"asked"</span>,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"good"</span>, <span class="st">"bad"</span>, <span class="st">"better"</span>, <span class="st">"best"</span>, <span class="st">"worst"</span>, <span class="st">"big"</span>, <span class="st">"small"</span>,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"little"</span>, <span class="st">"huge"</span>, <span class="st">"tiny"</span>, <span class="st">"old"</span>, <span class="st">"new"</span>, <span class="st">"young"</span>, <span class="st">"great"</span>,</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"nice"</span>, <span class="st">"mean"</span>, <span class="st">"strong"</span>, <span class="st">"weak"</span>, <span class="st">"happy"</span>, <span class="st">"sad"</span>,</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I"</span>, <span class="st">"me"</span>, <span class="st">"my"</span>, <span class="st">"mine"</span>, <span class="st">"you"</span>, <span class="st">"your"</span>, <span class="st">"yours"</span>,</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"he"</span>, <span class="st">"him"</span>, <span class="st">"his"</span>, <span class="st">"she"</span>, <span class="st">"her"</span>, <span class="st">"hers"</span>, <span class="st">"it"</span>, <span class="st">"its"</span>,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"we"</span>, <span class="st">"us"</span>, <span class="st">"our"</span>, <span class="st">"ours"</span>, <span class="st">"they"</span>, <span class="st">"them"</span>, <span class="st">"their"</span>, <span class="st">"theirs"</span>,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"yes"</span>, <span class="st">"no"</span>, <span class="st">"maybe"</span>, <span class="st">"okay"</span>, <span class="st">"really"</span>, <span class="st">"very"</span>, <span class="st">"just"</span>, <span class="st">"even"</span>, <span class="st">"still"</span>, <span class="st">"yet"</span>,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"oh"</span>, <span class="st">"uh"</span>, <span class="st">"um"</span>, <span class="st">"hmm"</span>, <span class="st">"ah"</span>, <span class="st">"haha"</span>, <span class="st">"lol"</span>, <span class="st">"hmm"</span>, <span class="st">"what"</span>,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"it"</span>, <span class="st">"the"</span>, <span class="st">"not"</span>, <span class="st">"is"</span>, <span class="st">"no"</span>, <span class="st">"of"</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co"># hide warnings for readability</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    warnings.simplefilter(<span class="st">"ignore"</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># custom red color range </span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    custom_reds <span class="op">=</span> [<span class="st">"#ffa07a"</span>, <span class="st">"#ff4c4c"</span>, <span class="st">"#d60000"</span>, <span class="st">"#a00000"</span>, <span class="st">"#600000"</span>]</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter for nouns only</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    df_word_freq1 <span class="op">=</span> df[df[<span class="st">"word_POS"</span>] <span class="op">==</span> <span class="st">"noun"</span>]</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove words with spaces or numbers</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    df_word_freq1 <span class="op">=</span> df_word_freq1[<span class="op">~</span>df_word_freq1[<span class="st">"word_US"</span>].<span class="bu">str</span>.contains(<span class="vs">r"\s|\d"</span>, na<span class="op">=</span><span class="va">False</span>, regex<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter out not significant words</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    df_word_freq1 <span class="op">=</span> df_word_freq1[<span class="op">~</span>df_word_freq1[<span class="st">"word_US"</span>].isin(stopwords)]</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># total occurrences of words per series</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    word_counts <span class="op">=</span> df_word_freq1.groupby([<span class="st">"img_series"</span>, <span class="st">"word_US"</span>])[<span class="st">"word_US"</span>].count().reset_index(name<span class="op">=</span><span class="st">"word_count"</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sort by frequency for each series (top 50)</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    top_n <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    word_counts_top <span class="op">=</span> word_counts.sort_values(by<span class="op">=</span><span class="st">"word_count"</span>, ascending<span class="op">=</span><span class="va">False</span>).groupby(<span class="st">"img_series"</span>).head(top_n)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get global min and max</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    global_min <span class="op">=</span> word_counts_top[<span class="st">"word_count"</span>].<span class="bu">min</span>()</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    global_max <span class="op">=</span> word_counts_top[<span class="st">"word_count"</span>].<span class="bu">max</span>()</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># function to map word count to the custom red color range</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> map_to_custom_reds(value, vmin, vmax):</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        norm_value <span class="op">=</span> (value <span class="op">-</span> vmin) <span class="op">/</span> (vmax <span class="op">-</span> vmin)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        color_index <span class="op">=</span> <span class="bu">int</span>(norm_value <span class="op">*</span> (<span class="bu">len</span>(custom_reds) <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> custom_reds[color_index]</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># question 2 plot 1: bar graphs</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">11</span>))</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over each series and create individual bar plots</span></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, series <span class="kw">in</span> <span class="bu">enumerate</span>(word_counts_top[<span class="st">'img_series'</span>].unique()):</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> axes[idx]</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> word_counts_top[word_counts_top[<span class="st">"img_series"</span>] <span class="op">==</span> series]</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>        max_value <span class="op">=</span> data[<span class="st">"word_count"</span>].<span class="bu">max</span>()</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        bar_colors <span class="op">=</span> [map_to_custom_reds(value, global_min, global_max) <span class="cf">for</span> value <span class="kw">in</span> data[<span class="st">"word_count"</span>]]</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        bars <span class="op">=</span> sns.barplot(</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>            x<span class="op">=</span><span class="st">"word_count"</span>, </span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>            y<span class="op">=</span><span class="st">"word_US"</span>, </span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>            data<span class="op">=</span>data, </span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>            ax<span class="op">=</span>ax,</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>            palette<span class="op">=</span>bar_colors</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># black edge color of bars</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> bar <span class="kw">in</span> bars.patches:</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>            bar.set_edgecolor(<span class="st">"black"</span>)</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>            bar.set_linewidth(<span class="dv">1</span>)</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># word frquency inside each bar</span></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, value <span class="kw">in</span> <span class="bu">enumerate</span>(data[<span class="st">"word_count"</span>]):</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>            text_color <span class="op">=</span> <span class="st">"white"</span> <span class="cf">if</span> series <span class="op">==</span> <span class="st">"Baki Dou 2"</span> <span class="kw">and</span> value <span class="op">==</span> max_value <span class="cf">else</span> <span class="st">"black"</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>            ax.text(value <span class="op">/</span> <span class="dv">2</span>, i, <span class="bu">str</span>(value), ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span>text_color, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># titling</span></span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>        adjusted_series <span class="op">=</span> series.replace(<span class="st">"Hanma_Baki"</span>, <span class="st">"Hanma Baki"</span>)</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>adjusted_series<span class="sc">}</span><span class="ss"> Series"</span></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>        ax.set_title(title, fontweight<span class="op">=</span><span class="st">'normal'</span>)</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># y-axis</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x-axis</span></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"Word Frequency"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"Word Frequency"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"Word Frequency"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># remove y-axis labels</span></span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a>        ax.set_xlim(<span class="dv">0</span>, data[<span class="st">"word_count"</span>].<span class="bu">max</span>())</span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="q2-bar1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="blog_files/figure-html/q2-bar1-output-1.png" width="1045" height="1044" class="figure-img"></p>
<figcaption>Figure 2.1: Bar graph showing top 50 most frequent nouns across three Baki manga series.</figcaption>
</figure>
</div>
</div>
</div>
<p>To better understand the impact of themes on the story of Baki, I decided to visualize the most common nouns present across all three manga series in the form of a combined bar graph. I began by cleaning my dataset to get a fair result of my visualization. The three main tasks of this are shown below:</p>
<p><strong>Stopword Removal:</strong> I removed the dataset of “stopwords”. An example of a common stopword is “the” or “be”. They are called this because they “stop” or are excluded in almost all natural language processing. They provide no significant meaning and appear very frequently, potentially swaying the results of word analysis if they are not filtered out. In the beginning of the code section above, I show a large list of common stopwords I excluded from my dataset for this graph.</p>
<p><strong>Additional Cleaning:</strong> I continued by filtering my dataframe to only include nouns, since these will provide me with the most amount of context and meaninful information to understand the themes of the manga work. I also removed words with spacing or numbers, as these can cause issues for proper visualization.</p>
<p>After performing the above cleaning, I put together my combined bar graphic of figure 2.1 above showning the 50 most common nouns in each manga series of Baki Dou 2, Baki Rahen, and Hanma Baki (graphs follow same order of left to right). For easier readability, the graphs were all colored by a set of 5 red colors, with darker red representing more frequency of a word and lighter red representing less frequency of a word.</p>
<p>The results of this graph are really interesting in that the word “Baki”, the name of the main character in <em>Grappler Baki</em>, is one of the most common nouns in all three series. In addition, words such as “Sumo”, “body”, “fighting”, “strongest”, “warrior”, “death”, and “man” all clearly represent the themes that the story of Grappler Baki explores. This relationship shows that the manga is character-centric, as they play an important role in the Baki story.</p>
</section>
<section id="parts-of-speech-distribution" class="level2">
<h2 class="anchored" data-anchor-id="parts-of-speech-distribution">Parts of Speech Distribution</h2>
<div id="cell-Q2-bar2" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># filter dataset &amp; remove nulls</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df_filtered4 <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">"word_POS"</span>, <span class="st">"img_series"</span>])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># count occurrences of each POS per series</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>pos_counts <span class="op">=</span> df_filtered4.groupby([<span class="st">"img_series"</span>, <span class="st">"word_POS"</span>])[<span class="st">"word_POS"</span>].count().reset_index(name<span class="op">=</span><span class="st">"count"</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># pivot table for stacked bar format</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>pos_pivot <span class="op">=</span> pos_counts.pivot(index<span class="op">=</span><span class="st">"img_series"</span>, columns<span class="op">=</span><span class="st">"word_POS"</span>, values<span class="op">=</span><span class="st">"count"</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate total words in each series</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>total_words_per_series <span class="op">=</span> pos_pivot.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize each part of speech count by total words in the series</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>pos_pivot_normalized <span class="op">=</span> pos_pivot.div(total_words_per_series, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># create subplots</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">11</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># question 2 plot 2: bar graphs</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, series <span class="kw">in</span> <span class="bu">enumerate</span>(pos_pivot_normalized.index):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pos_pivot_normalized.loc[series].sort_values(ascending<span class="op">=</span><span class="va">False</span>)  <span class="co"># sort by proportion</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    data.plot(kind<span class="op">=</span><span class="st">"bar"</span>, stacked<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">"red"</span>, edgecolor<span class="op">=</span><span class="st">"black"</span>, linewidth<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    ax.set_xticklabels(ax.get_xticklabels(), rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    adjusted_series <span class="op">=</span> series.replace(<span class="st">"Hanma_Baki"</span>, <span class="st">"Hanma Baki"</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>adjusted_series<span class="sc">}</span><span class="ss"> Series"</span>, fontweight<span class="op">=</span><span class="st">"normal"</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"Parts of Speech"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Proportion"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="q2-bar2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="blog_files/figure-html/q2-bar2-output-1.png" width="1045" height="1044" class="figure-img"></p>
<figcaption>Figure 2.2: Bar graph of normalized distributions of POS across three Baki manga series.</figcaption>
</figure>
</div>
</div>
</div>
<p>I continued my thematic analysis of Baki by visualizing another bar graph of figure 2.2. This one differs from figure 2.1 in that it visulizes the normalized distribution of parts of speech across the three Baki series used in my dataset. Normalized means adjusting to take into consideration of the proportion of parts of speech across series instead of just total number of occurrences.</p>
<p>The result of the above figure surprised me greatly, as the distribution of parts of speech across the series is nearly identical, with nouns, unknown, and verbs dominating the total proportion. This means that the way that <em>Grappler Baki</em> is written has not changed over the past 20 years of these manga series being published. This also shows that the story of Baki hasn’t changed its direction and themes and follows the same general pattern of story-telling.</p>
</section>
<section id="tf-idf-insights" class="level2">
<h2 class="anchored" data-anchor-id="tf-idf-insights">TF-IDF Insights</h2>
<div id="cell-Q2-bar3" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hide warnings for readability</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    warnings.simplefilter(<span class="st">"ignore"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert stopwords set to list</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    stopwords_list <span class="op">=</span> <span class="bu">list</span>(stopwords)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter dataset &amp; remove nulls</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    df_filtered_tfidf <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">"word_US"</span>, <span class="st">"img_series"</span>])</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only nouns</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    df_filtered_tfidf <span class="op">=</span> df_filtered_tfidf[df_filtered_tfidf[<span class="st">"word_POS"</span>] <span class="op">==</span> <span class="st">"noun"</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove stopwords from "word_US" column</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    df_filtered_tfidf <span class="op">=</span> df_filtered_tfidf[<span class="op">~</span>df_filtered_tfidf[<span class="st">"word_US"</span>].isin(stopwords_list)]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># put all words into a single document per series</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    series_documents <span class="op">=</span> df_filtered_tfidf.groupby(<span class="st">"img_series"</span>)[<span class="st">"word_US"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join(x)).reset_index()</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TF-IDF vectorizer setup with custom stopwords</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">300</span>, stop_words<span class="op">=</span>stopwords_list)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    tfidf_matrix <span class="op">=</span> vectorizer.fit_transform(series_documents[<span class="st">"word_US"</span>])</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># matrix to dataFrame</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    tfidf_df <span class="op">=</span> pd.DataFrame(tfidf_matrix.toarray(), index<span class="op">=</span>series_documents[<span class="st">"img_series"</span>], columns<span class="op">=</span>vectorizer.get_feature_names_out())</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># top 20 highest TF-IDF words per series</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    top_n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    top_words_per_series <span class="op">=</span> {}</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> series <span class="kw">in</span> tfidf_df.index:</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        top_words <span class="op">=</span> tfidf_df.loc[series].nlargest(top_n)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        top_words_per_series[series] <span class="op">=</span> top_words</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># colors</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    cmap <span class="op">=</span> plt.cm.Reds</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    norm <span class="op">=</span> mcolors.Normalize(vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Normalize between 0 and 1 for the color map</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># question 2 plot 3: TF-IDF</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">11</span>))</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (series, words) <span class="kw">in</span> <span class="bu">enumerate</span>(top_words_per_series.items()):</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> axes[idx]</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># normalize TF-IDF values for each word to create color gradient</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        normalized_values <span class="op">=</span> (words.values <span class="op">-</span> words.values.<span class="bu">min</span>()) <span class="op">/</span> (words.values.<span class="bu">max</span>() <span class="op">-</span> words.values.<span class="bu">min</span>())</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        colors <span class="op">=</span> [cmap(norm(val)) <span class="cf">for</span> val <span class="kw">in</span> normalized_values]</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        sns.barplot(x<span class="op">=</span>words.values, y<span class="op">=</span>words.index, ax<span class="op">=</span>ax, palette<span class="op">=</span>colors, edgecolor<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f"</span><span class="sc">{</span>series<span class="sc">}</span><span class="ss"> Series"</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        ax.set_xlabel(<span class="st">"TF-IDF Score"</span>)</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        ax.set_ylabel(<span class="st">"Word (English)"</span>)</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x-axis label</span></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"TF-IDF Score"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># y-axis label</span></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># remove x-axis</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if idx == 0:</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ax.set_xlabel('')</span></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if idx == 2:</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ax.set_xlabel('')</span></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># remove y-axis labels</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># set x-axis ticks to intervals of 0.15</span></span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>        ax.set_xticks([i <span class="op">*</span> <span class="fl">0.15</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">int</span>(words.values.<span class="bu">max</span>() <span class="op">//</span> <span class="fl">0.15</span>) <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="q2-bar3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="blog_files/figure-html/q2-bar3-output-1.png" width="1045" height="1044" class="figure-img"></p>
<figcaption>Figure 2.3: Bar graph top 20 most important words across three Baki manga series.</figcaption>
</figure>
</div>
</div>
</div>
<p>The final visualization of figure 2.3 shows the results of TF-IDF analysis on the dataset in a combined bar graph format. The term when written out fully reads as term frequency-inverse document frequency and this is a technique in data analysis to measure the importance of words in a given document. During this process, a certain weight is applied to each word in a given dataset, meaning “heavier” words hold more meaning while “lighter” words hold less meaning. Weight of a word decreases by how frequently it appears in the overall word list. In general TF-IDF highlights words that are distinctive rather than common.</p>
<p>In the above visualization of the top 20 most important words in each Baki series, the bars are colored with a red hue that decreases in intensity depending on TF-IDF score. The graph shows a similarity to the result in figure 2.1 of the most common nouns in all three Baki manga series. Names and words relating to the themes of the Grappler Baki story are shown, representing that characters are central to the story of Baki.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The <em>Grappler Baki</em> manga maintains a consistent narrative style, with language reinforcing themes of strength and growth. OCR analysis reveals that writing style complexity negatively affects text extraction accuracy. This project shows how OCR bridges the gap in understanding manga, highlighting the value of combining technology with storytelling.</p>
<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-baki_douTwo_2025" class="csl-entry" role="listitem">
<span>“Baki Dou 2 Manga Panels Download Page.”</span> 2025. <a href="https://dl-raw.ac/%e5%88%83%e7%89%99%e9%81%93-%e7%ac%ac01-20%e5%b7%bb-baki-dou-vol-01-20/" class="uri">https://dl-raw.ac/%e5%88%83%e7%89%99%e9%81%93-%e7%ac%ac01-20%e5%b7%bb-baki-dou-vol-01-20/</a>.
</div>
<div id="ref-baki_rahen_2025" class="csl-entry" role="listitem">
<span>“Baki Rahen Manga Panels Download Page.”</span> 2025. <a href="https://dl-raw.ac/%e5%88%83%e7%89%99%e3%82%89%e3%81%b8%e3%82%93-raw/" class="uri">https://dl-raw.ac/%e5%88%83%e7%89%99%e3%82%89%e3%81%b8%e3%82%93-raw/</a>.
</div>
<div id="ref-geeks_OCR_2023" class="csl-entry" role="listitem">
GeeksForGeeks. 2023. <span>“What Is Optical Character Recognition (OCR)?”</span> <a href="https://www.geeksforgeeks.org/what-is-optical-character-recognition-ocr/" class="uri">https://www.geeksforgeeks.org/what-is-optical-character-recognition-ocr/</a>.
</div>
<div id="ref-documentation_OCR_2025" class="csl-entry" role="listitem">
github. 2025. <span>“PaddleOCR Documentation.”</span> <a href="https://github.com/PaddlePaddle/PaddleOCR/blob/main/README_en.md" class="uri">https://github.com/PaddlePaddle/PaddleOCR/blob/main/README_en.md</a>.
</div>
<div id="ref-hanma_baki_2025" class="csl-entry" role="listitem">
<span>“Hanma Baki Manga Panels Download Page.”</span> 2025. <a href="https://dl-raw.ac/%e7%af%84%e9%a6%ac%e5%88%83%e7%89%99-hanma-baki/" class="uri">https://dl-raw.ac/%e7%af%84%e9%a6%ac%e5%88%83%e7%89%99-hanma-baki/</a>.
</div>
<div id="ref-IBM_OCR_2024" class="csl-entry" role="listitem">
IBM. 2024. <span>“What Is Optical Character Recognition (OCR)?”</span> <a href="https://www.ibm.com/think/topics/optical-character-recognition" class="uri">https://www.ibm.com/think/topics/optical-character-recognition</a>.
</div>
<div id="ref-pydata_ocr_2025" class="csl-entry" role="listitem">
PyData. 2025. <span>“OCR Breakdown: Performance of OCR on Japanese Text.”</span> <a href="https://www.youtube.com/watch?v=OitWeFVvShc" class="uri">https://www.youtube.com/watch?v=OitWeFVvShc</a>.
</div>
<div id="ref-tutorial_OCR_2021" class="csl-entry" role="listitem">
Renotte, Nicholas. 2021. <span>“Rip Out Drug Labels Using Deep Learning with PaddleOCR &amp; Python.”</span> <a href="https://www.youtube.com/watch?v=t5xwQguk9XU" class="uri">https://www.youtube.com/watch?v=t5xwQguk9XU</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb8" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Grappler Baki Word Analysis"</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "A Data Science Approach to Understanding Language in Baki"</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Andrew Nemkov"</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="an">nocite:</span><span class="co"> |</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">  @*</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> false</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: default</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">    rendering: embed-resources</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="al">![Manga Panel of Hanma Baki.](blog_assets/p2Blog.png)</span>{fig-alt="One of numerous manga panels from the Baki manga."}</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="fu"># Motivation &amp; Background</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>**"強くあろうとする姿はかくも美しい"**</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>The short Japanese phrase above translates literally to "That who has a strong frame is beautiful". In a more general sense, it conveys the idea that one's body, once properly trained and developed, expresses more beauty than traditional features such as one's face.</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>This often complicated and multi-layered idea is a foundational theme in the Japanese comic book style manga of *Grappler Baki*. In the story, a 17 year old boy by the name of Baki spends countless hours training and developing himself physically and mentally to one day stand in front of his father, the "strongest creature alive", and challenge him in martial combat.</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>*Grappler Baki* is an example of one of today's few globally recognized Japanese works of visual and textual art that pushes the boundaries to what it means to be masculine. Popular as it is, the work's origin creates a barrier for those outside of Japan to interact with the manga. As a result of this language gap, the need for this project was born. </span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>Utilizing data science techniques, I aim to bridge this gap in linguistics by analyzing the words used withing Baki's universe. Utilizing the tools of natural language processing, I seek to provide a deeper understanding of the work's narrative structure and themes that define *Grappler Baki*.</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="fu"># Dataset Foundation</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>To undertake such a difficult task of bridging the gap between my English and the Japanese of Grappler Baki, I first needed to create a proper dataset that would contains all the written content used to describe Baki's story over a large assortment of Japanese manga panels. For this, I discovered a site known as <span class="co">[</span><span class="ot">dl-raw.ac</span><span class="co">](https://dl-raw.ac/)</span> that contained downloadable content on various Japanese manga, broken down by series. In this site, I downloaded pages for the three Baki series of my personal choice: Baki Rahen manga series (see <span class="co">[</span><span class="ot">Baki Rahen Page</span><span class="co">](https://dl-raw.ac/%e5%88%83%e7%89%99%e3%82%89%e3%81%b8%e3%82%93-raw/)</span>), Baki Dou 2 manga series (see <span class="co">[</span><span class="ot">Baki Dou 2 Page</span><span class="co">](https://dl-raw.ac/%e5%88%83%e7%89%99%e9%81%93-%e7%ac%ac01-20%e5%b7%bb-baki-dou-vol-01-20/)</span>), and Hanma Baki manga series (see <span class="co">[</span><span class="ot">Hanma Baki Page</span><span class="co">](https://dl-raw.ac/%e7%af%84%e9%a6%ac%e5%88%83%e7%89%99-hanma-baki/)</span>). In total, the three downloads contained roughly 4000 Japanese manga pages describing various parts of Baki's life as a fighter.</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Validity of dl-raw.ac Website</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>Some things to note about the website I utilized to get my data:</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The site is publicly accessible. </span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The analysis of this project was performed for non-commercial purposes only.</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>All source citations were provided.</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>The data used in this project will not be redistributed.</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>After gathering the source of my data, I needed a tool that I could use to extract the Japanese text from these images and turn the result into a computer-readable format. For this I utilized Optical Character Recognition (OCR), which would take in a Japanese manga image as input and output extracted Japanese phrases with each having a confidence score for how correctly the model thinks it extracted that portion of text. </span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>For a detailed explanation on the process of using this machine learning, please see below: </span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="co">[</span><span class="ot">GeekForGeeks site OCR explanation</span><span class="co">](https://www.geeksforgeeks.org/what-is-optical-character-recognition-ocr/)</span> and <span class="co">[</span><span class="ot">IBM site OCR explanation</span><span class="co">](https://www.ibm.com/think/topics/optical-character-recognition)</span></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="co">[</span><span class="ot">Documentation of PaddleOCR</span><span class="co">](https://github.com/PaddlePaddle/PaddleOCR/blob/main/README_en.md)</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="co">[</span><span class="ot">Tutorial Video for PaddleOCR</span><span class="co">](https://www.youtube.com/watch?v=t5xwQguk9XU)</span></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>**Japanese Overview**</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>Further context is required to better understand the results of my project. In this part, I will explain the basic way that the Japanese writing system functions. In short, the Japanese language is written in a combination of three writing systems: hiragana, katakana, and kanji. Hiragana and katakana are "kana" or system of Japanese alphabet, where one letter represents a sound. Hiragana is used for words originated from Japan, while katakana is used to represent foreign words adapted from outside Japan. On the other hand, kanji represent logographic characters, or ones where a letter represents a concept or idea instead of a sound. For this reason, kanji are more complicated that hiragana and katakana. This basic information will be crucial to understand several of my project's variables.</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dataset Creation</span></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>**Setup**</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>To begin an exaplanation of the OCR code used in this project, it is essential to start with the correct python libraries. Almost all were utilized in the data preparation process. Specifically, I used the **cv2** python library for file reading and image preprocessing, the **re** python library for cleaning of words, csv to read my extraction into a dataset, **os** for file path creation, the **gc** python library for cleaning memory, the **fugashi** python library to separate phrases into words, the **Counter** python library to count word frequency, the **PaddleOCR** python library to import the proper OCR model, and the **Translator** python library to translate extracted Japanese words to English.</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>The data creation process continued with utilizing the above libraries to create a meaninful dataset for analysis. I used figashi to tokenize words as well as identify each word's part of speech and in addition to this, those words that were not identified into groups were set as "unknown". I continued by translating my Japanese words into English using Google translate as well as calculating the Japanese ratios of types of characters in each word. Each word was given three ratios for the proportion of hiragana, katakana, and kanji characters in each word.</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a><span class="fu">## Further Data Creation Information</span></span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>Please note an important aspect of the way that more extractions are added to the dataset. Column names are written so that if they currently exist in the dataset, then new ones will not be added, but if a dataset has no headers then the provided will be added before all other information.</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>In addition, to limit performance issues of the Visual Studio Code application and OCR heavy processing requirement, I added a small amount of code to clean the memory of the process after an image is processed and added to the dataset.</span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>**Parameter Tuning**</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>The parameters of the OCR model for this project are just as important as creating the columns of the dataset. Finding the right parameters to use took lots of experimentation, as I kept slightly adjusting the OCR's rec_batch_num, det_db_box_thresh, det_db_unclip_ratio, rec_max_len, and drop_score. Below I explained these parameters further below:</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The rec_batch_num represents the model's batch size processing parameter that when increased, increases the speed of the machine learning's processing. </span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The det_db_box_thresh parameter represents the box detection confidence, which when increased changes the model to only detect more clearer text boxes. </span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>On the other hand, det_db_unclip_ratio when increased makes the model detect more words or symbols. </span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>The rec_max_len parameter is easier to understand, as this simply limits the total length of an extracted phrase. </span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>The final parameter of drop_score limits the maximum score that the OCR model can process and add the dataset, as all phrases extracted with a lower score than the threshold will be discarded.</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a>**Features**</span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>For final clarity of the visualizations and results of the project, below are simple explanations of all the features of the dataset:</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**word_JAP**: Japanese word from extracted Japanese phrase.</span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**word_US**: English word translated from word_JAP.</span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**word_POS**: Part of speech for word_JAP.</span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**phrase_JAP**: Japanese phrase extracted from Baki manga JPG image.</span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**img_title**: Title of Baki manga JPG image.</span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**img_series**: Manga series of Baki manga JPG image.</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**length**: Length of word_JAP.</span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a><span class="ss">8. </span>**confidence**: OCR confidence score of extracted Japanese phrase.</span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a><span class="ss">9. </span>**word_freq**: Decimal value of how often a particular Japanese word appears in dataset (calculated separately from other data creation steps for simplicity)</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a><span class="ss">10. </span>**hiragana_ratio**: Ratio of hiragana characters in word_JAP.</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a><span class="ss">11. </span>**katakana_ratio**: Ratio of katakana characters in word_JAP.</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a><span class="ss">12. </span>**kanji_ratio**: Ratio of kanji characters in word_JAP.</span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a><span class="fu"># Example Extraction</span></span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a>Below is a short demonstration of the process of the PaddleOCR model I utilized in my project. The machine learning model is given an image to analyze, it identifies and extracts Japanese text, proper cleaning and calculations are performed with these extracted phrases, and the result is recorded in the dataset.</span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a>**Step 1: Obtain Image**</span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a>Below is an example of one of 4000 Japanese manga panels from the Grappler Baki manga. In this specific case, the image comes at the end of a chapter, which is why the right half is black while the left shows drawings and text.</span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a><span class="al">![Example Japanese manga panel named DL-Raw.Net_48 (2).jpg.](blog_assets/Implementation1.png)</span>{fig-alt="Image showing PaddleOCR identifying text in DL-Raw.Net_48 (2).jpg image."}</span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true" tabindex="-1"></a>The process begins with an image input. In this example, I used a image with few words for simplicity titled DL-Raw.Net_48 (2).jpg. The OCR model runs its machine learning algorithm and identifies the Japanese text seen in the bright red box above.</span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true" tabindex="-1"></a>**Step 2: Extract Text**</span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true" tabindex="-1"></a><span class="al">![Test image python OCR output.](blog_assets/Implementation2.png)</span>{fig-alt="Image showing test run of PaddleOCR code on image named DL-Raw.Net_48 (2).jpg."}</span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true" tabindex="-1"></a>The model takes the identified text and formats it into a computer readable format. After this, the OCR continues to attempt to identify any more text phrases, following the repreating process of identification and transformation in format until no more text can be identified on the image. When this occurs, a numered success message is given in the output, showing the ending of OCR process on the DL-Raw.Net_48 (2).jpg image.</span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true" tabindex="-1"></a>**Step 3: Add to Dataset**</span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true" tabindex="-1"></a><span class="al">![Test image dataset implementation.](blog_assets/Implementation3.png)</span>{fig-alt="Image showing extracted information and calculated features obtained by running PaddleOCR on image named DL-Raw.Net_48 (2).jpg."}</span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true" tabindex="-1"></a>The identified information of the example image is the actual extracted phrase and the model's confidence of this extraction. These two key pieces are input into a dataset. Following this, my own code performs several steps of further calculations from both the information about the image and the Japanese text that was extracted. </span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true" tabindex="-1"></a>The result of my calculations and further data preparation is seen above with a small dataset including headers, the extraced Japanese phrase of 他の監, and two words of 他 and 監 which were obtained from this phrase from the above example image. It is important to note that the symbol の is read as "no" and serves a grammatical phrase of the role, explaining why there are two words and not three in the example dataset. </span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true" tabindex="-1"></a><span class="fu"># Dataset Preprocessing </span></span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: First-5-Rows</span></span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 0.5: First five rows of dataset."</span></span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gaussian_kde</span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> LinearSegmentedColormap</span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> mpatches</span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.colors <span class="im">as</span> mcolors</span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> NMF</span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset name</span></span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true" tabindex="-1"></a>csv_file <span class="op">=</span> <span class="vs">r"C:\Users\andne\OneDrive\Pictures\Capstone1\capstone\(1)-main\(1)-codeAndData\realData.csv"</span></span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true" tabindex="-1"></a><span class="co"># make dataframe of data</span></span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(csv_file)</span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true" tabindex="-1"></a><span class="co"># remove outliers (words longer than 10 characters)</span></span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true" tabindex="-1"></a>df_filtered <span class="op">=</span> df[df[<span class="st">"length"</span>] <span class="op">&lt;=</span> <span class="dv">10</span>].copy()</span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true" tabindex="-1"></a>display(df_filtered.head())</span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true" tabindex="-1"></a>After successfully choosing an OCR model, performing the necessary setup, and adjusting the model's parameters, I began my word analysis by importing the necessary python libraries. </span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-174"><a href="#cb8-174" aria-hidden="true" tabindex="-1"></a>Some important ones I mentioned below:</span>
<span id="cb8-175"><a href="#cb8-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-176"><a href="#cb8-176" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>I calculate jittering in scatter plot points using the the **gaussian_kde** library.</span>
<span id="cb8-177"><a href="#cb8-177" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>I perform a TF-IDf analysis to obtain importance of words in a dataset using the **TfidfVectorizer** library.</span>
<span id="cb8-178"><a href="#cb8-178" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>I perform NMF analysis to group words into distinct themes using the **NMF** library.</span>
<span id="cb8-179"><a href="#cb8-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-180"><a href="#cb8-180" aria-hidden="true" tabindex="-1"></a>In addition to the standard method of reading in a CSV dataset, I also filtered the data to exclude words longer than 10 characters, as this was clearly an tokenization error. This means some words were not correctly split from their parent phrases and therefore proper word analysis can't be performed on them. As a result, I cleaned the data to include only single word entries for the main word_JAP column.</span>
<span id="cb8-181"><a href="#cb8-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-182"><a href="#cb8-182" aria-hidden="true" tabindex="-1"></a><span class="fu"># OCR Confidence and Word Complexity</span></span>
<span id="cb8-183"><a href="#cb8-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-184"><a href="#cb8-184" aria-hidden="true" tabindex="-1"></a>The first part of my analysis involved researching the correlations between an OCR model's confidence and an extracted word's complexity. In this case complexity considers both the length of the extracted Japanese word as well as the types of Japanese characters that make up this word. Separate analysis of these two simpler relationships can yield significant understanding of what variables most notably decrease an OCR model's confidence score for a extracted phrase, allowing for better future application of the project.</span>
<span id="cb8-185"><a href="#cb8-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-186"><a href="#cb8-186" aria-hidden="true" tabindex="-1"></a><span class="fu">## Word Length Trends</span></span>
<span id="cb8-187"><a href="#cb8-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-190"><a href="#cb8-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-191"><a href="#cb8-191" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Q1-scatter</span></span>
<span id="cb8-192"><a href="#cb8-192" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 1.1: Scatter plot showing relationship between OCR confidence and word length."</span></span>
<span id="cb8-193"><a href="#cb8-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-194"><a href="#cb8-194" aria-hidden="true" tabindex="-1"></a><span class="co"># filter words with more than 15 characters</span></span>
<span id="cb8-195"><a href="#cb8-195" aria-hidden="true" tabindex="-1"></a>long_words <span class="op">=</span> df[df[<span class="st">"word_JAP"</span>].<span class="bu">str</span>.<span class="bu">len</span>() <span class="op">&gt;</span> <span class="dv">15</span>][[<span class="st">"word_JAP"</span>, <span class="st">"word_US"</span>]]</span>
<span id="cb8-196"><a href="#cb8-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-197"><a href="#cb8-197" aria-hidden="true" tabindex="-1"></a><span class="co"># print(long_words)</span></span>
<span id="cb8-198"><a href="#cb8-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-199"><a href="#cb8-199" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb8-200"><a href="#cb8-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-201"><a href="#cb8-201" aria-hidden="true" tabindex="-1"></a><span class="co"># jitter strength</span></span>
<span id="cb8-202"><a href="#cb8-202" aria-hidden="true" tabindex="-1"></a>jitter_strength <span class="op">=</span> <span class="fl">0.1</span>  <span class="co"># Adjust this value as needed</span></span>
<span id="cb8-203"><a href="#cb8-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-204"><a href="#cb8-204" aria-hidden="true" tabindex="-1"></a><span class="co"># create jittered columns</span></span>
<span id="cb8-205"><a href="#cb8-205" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">"jittered_length"</span>] <span class="op">=</span> df_filtered[<span class="st">"length"</span>] <span class="op">+</span> np.random.uniform(<span class="op">-</span>jitter_strength, jitter_strength, <span class="bu">len</span>(df_filtered))</span>
<span id="cb8-206"><a href="#cb8-206" aria-hidden="true" tabindex="-1"></a>df_filtered[<span class="st">"jittered_confidence"</span>] <span class="op">=</span> df_filtered[<span class="st">"confidence"</span>] <span class="op">+</span> np.random.uniform(<span class="op">-</span>jitter_strength, jitter_strength, <span class="bu">len</span>(df_filtered))</span>
<span id="cb8-207"><a href="#cb8-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-208"><a href="#cb8-208" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb8-209"><a href="#cb8-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-210"><a href="#cb8-210" aria-hidden="true" tabindex="-1"></a><span class="co"># KDE calculation using jittered values</span></span>
<span id="cb8-211"><a href="#cb8-211" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> np.vstack([df_filtered[<span class="st">'jittered_length'</span>], df_filtered[<span class="st">'jittered_confidence'</span>]])</span>
<span id="cb8-212"><a href="#cb8-212" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> gaussian_kde(xy)  </span>
<span id="cb8-213"><a href="#cb8-213" aria-hidden="true" tabindex="-1"></a>density <span class="op">=</span> kde(xy)  </span>
<span id="cb8-214"><a href="#cb8-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-215"><a href="#cb8-215" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize density values</span></span>
<span id="cb8-216"><a href="#cb8-216" aria-hidden="true" tabindex="-1"></a>norm_density <span class="op">=</span> (density <span class="op">-</span> np.<span class="bu">min</span>(density)) <span class="op">/</span> (np.<span class="bu">max</span>(density) <span class="op">-</span> np.<span class="bu">min</span>(density))</span>
<span id="cb8-217"><a href="#cb8-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-218"><a href="#cb8-218" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb8-219"><a href="#cb8-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-220"><a href="#cb8-220" aria-hidden="true" tabindex="-1"></a><span class="co"># custom red palette (light red to dark red)</span></span>
<span id="cb8-221"><a href="#cb8-221" aria-hidden="true" tabindex="-1"></a>custom_reds <span class="op">=</span> LinearSegmentedColormap.from_list(</span>
<span id="cb8-222"><a href="#cb8-222" aria-hidden="true" tabindex="-1"></a>    <span class="st">"custom_reds"</span>, [<span class="st">"#ffa07a"</span>, <span class="st">"#f08080"</span>, <span class="st">"#ff0000"</span>, <span class="st">"#ce2029"</span>, <span class="st">"#8b0000"</span>]</span>
<span id="cb8-223"><a href="#cb8-223" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-224"><a href="#cb8-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-225"><a href="#cb8-225" aria-hidden="true" tabindex="-1"></a><span class="co"># question 1 plot 1: scatter plot with density-based coloring</span></span>
<span id="cb8-226"><a href="#cb8-226" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">6.5</span>, <span class="fl">4.5</span>))</span>
<span id="cb8-227"><a href="#cb8-227" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(</span>
<span id="cb8-228"><a href="#cb8-228" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>df_filtered[<span class="st">"jittered_length"</span>], </span>
<span id="cb8-229"><a href="#cb8-229" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>df_filtered[<span class="st">"jittered_confidence"</span>], </span>
<span id="cb8-230"><a href="#cb8-230" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb8-231"><a href="#cb8-231" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span>norm_density,</span>
<span id="cb8-232"><a href="#cb8-232" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>custom_reds,  <span class="co"># Apply custom red gradient</span></span>
<span id="cb8-233"><a href="#cb8-233" aria-hidden="true" tabindex="-1"></a>    edgecolor<span class="op">=</span><span class="va">None</span></span>
<span id="cb8-234"><a href="#cb8-234" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-235"><a href="#cb8-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-236"><a href="#cb8-236" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression line</span></span>
<span id="cb8-237"><a href="#cb8-237" aria-hidden="true" tabindex="-1"></a>sns.regplot(x<span class="op">=</span>df_filtered[<span class="st">"jittered_length"</span>], y<span class="op">=</span>df_filtered[<span class="st">"jittered_confidence"</span>], scatter<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">"red"</span>, line_kws<span class="op">=</span>{<span class="st">"linewidth"</span>: <span class="dv">2</span>})</span>
<span id="cb8-238"><a href="#cb8-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-239"><a href="#cb8-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Set y-axis limit between 0.65 and 1</span></span>
<span id="cb8-240"><a href="#cb8-240" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.65</span>, <span class="dv">1</span>)</span>
<span id="cb8-241"><a href="#cb8-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-242"><a href="#cb8-242" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Word Length"</span>)</span>
<span id="cb8-243"><a href="#cb8-243" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"OCR Confidence"</span>)</span>
<span id="cb8-244"><a href="#cb8-244" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.title("Scatter Plot: OCR Confidence vs. Word Length (With Jitter &amp; Density Coloring)")</span></span>
<span id="cb8-245"><a href="#cb8-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-246"><a href="#cb8-246" aria-hidden="true" tabindex="-1"></a>legend_labels <span class="op">=</span> [</span>
<span id="cb8-247"><a href="#cb8-247" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#8b0000"</span>, label<span class="op">=</span><span class="st">"Very High Density"</span>),</span>
<span id="cb8-248"><a href="#cb8-248" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#ce2029"</span>, label<span class="op">=</span><span class="st">"High Density"</span>),</span>
<span id="cb8-249"><a href="#cb8-249" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#ff0000"</span>, label<span class="op">=</span><span class="st">"Medium Density"</span>),</span>
<span id="cb8-250"><a href="#cb8-250" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#f08080"</span>, label<span class="op">=</span><span class="st">"Low Density"</span>),</span>
<span id="cb8-251"><a href="#cb8-251" aria-hidden="true" tabindex="-1"></a>    mpatches.Patch(color<span class="op">=</span><span class="st">"#ffa07a"</span>, label<span class="op">=</span><span class="st">"Very Low Density"</span>),</span>
<span id="cb8-252"><a href="#cb8-252" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb8-253"><a href="#cb8-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-254"><a href="#cb8-254" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_labels, title<span class="op">=</span><span class="st">"Density"</span>, loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb8-255"><a href="#cb8-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-256"><a href="#cb8-256" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-257"><a href="#cb8-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-258"><a href="#cb8-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-259"><a href="#cb8-259" aria-hidden="true" tabindex="-1"></a>Analysis of the relationship between OCR confidence and word complexity begins by understanding the relationship between confidence and word length. I originally speculated that longer words are inherently more complex, therefore it would be more difficult for the model to extract them. </span>
<span id="cb8-260"><a href="#cb8-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-261"><a href="#cb8-261" aria-hidden="true" tabindex="-1"></a>To test this theory I wrote a scatter plot depicting the correlation between word length and OCR confidence. The original result was poorly visualized, so I implemented jittering of the scatterplot points for minimum variety of spacing, as well as added custom labels for five levels of density of points ranging from "Very High Density" to "Very Low Density". These labels were used to color the points in the graph, with darker red representing higher density and lighter red representing lower density. One final addition to the graphic was the use of a line-of-best-fit to help point the relationship between the two variables.</span>
<span id="cb8-262"><a href="#cb8-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-263"><a href="#cb8-263" aria-hidden="true" tabindex="-1"></a>The results of these adjustments are seen above in figure 1.1, where the features of word length and OCR confidence is positive (unlike my original guess of the relationship being negative). This means that as a Japanese word's length increases, the chance of it being extracted with higher OCR confidence increases. This result may be explained by the nature of how Japanese words are written, as words written with more complicated characters tend to often be shorter than those written with simpler characters.</span>
<span id="cb8-264"><a href="#cb8-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-265"><a href="#cb8-265" aria-hidden="true" tabindex="-1"></a><span class="fu">## OCR Confidence by Character Type</span></span>
<span id="cb8-266"><a href="#cb8-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-269"><a href="#cb8-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-270"><a href="#cb8-270" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Q1-box</span></span>
<span id="cb8-271"><a href="#cb8-271" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 1.2: Box plot showing relationship between OCR confidence and Japanese writing systems."</span></span>
<span id="cb8-272"><a href="#cb8-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-273"><a href="#cb8-273" aria-hidden="true" tabindex="-1"></a><span class="co"># hide warnings for readability</span></span>
<span id="cb8-274"><a href="#cb8-274" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb8-275"><a href="#cb8-275" aria-hidden="true" tabindex="-1"></a>    warnings.simplefilter(<span class="st">"ignore"</span>)</span>
<span id="cb8-276"><a href="#cb8-276" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-277"><a href="#cb8-277" aria-hidden="true" tabindex="-1"></a>    <span class="co"># function to find dominant character type</span></span>
<span id="cb8-278"><a href="#cb8-278" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> classify_character_type(row):</span>
<span id="cb8-279"><a href="#cb8-279" aria-hidden="true" tabindex="-1"></a>        max_ratio <span class="op">=</span> <span class="bu">max</span>(row[<span class="st">"hiragana_ratio"</span>], row[<span class="st">"katakana_ratio"</span>], row[<span class="st">"kanji_ratio"</span>])</span>
<span id="cb8-280"><a href="#cb8-280" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> max_ratio <span class="op">==</span> row[<span class="st">"kanji_ratio"</span>]:</span>
<span id="cb8-281"><a href="#cb8-281" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"Kanji"</span></span>
<span id="cb8-282"><a href="#cb8-282" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> max_ratio <span class="op">==</span> row[<span class="st">"katakana_ratio"</span>]:</span>
<span id="cb8-283"><a href="#cb8-283" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"Katakana"</span></span>
<span id="cb8-284"><a href="#cb8-284" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-285"><a href="#cb8-285" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"Hiragana"</span></span>
<span id="cb8-286"><a href="#cb8-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-287"><a href="#cb8-287" aria-hidden="true" tabindex="-1"></a>    <span class="co"># apply classification</span></span>
<span id="cb8-288"><a href="#cb8-288" aria-hidden="true" tabindex="-1"></a>    df_filtered[<span class="st">"char_type"</span>] <span class="op">=</span> df_filtered.<span class="bu">apply</span>(classify_character_type, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-289"><a href="#cb8-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-290"><a href="#cb8-290" aria-hidden="true" tabindex="-1"></a>    <span class="co"># question 1 plot 2: box plot</span></span>
<span id="cb8-291"><a href="#cb8-291" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="fl">7.5</span>, <span class="fl">5.5</span>))</span>
<span id="cb8-292"><a href="#cb8-292" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(</span>
<span id="cb8-293"><a href="#cb8-293" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">"char_type"</span>, </span>
<span id="cb8-294"><a href="#cb8-294" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">"confidence"</span>, </span>
<span id="cb8-295"><a href="#cb8-295" aria-hidden="true" tabindex="-1"></a>        data<span class="op">=</span>df_filtered, </span>
<span id="cb8-296"><a href="#cb8-296" aria-hidden="true" tabindex="-1"></a>        palette<span class="op">=</span><span class="st">"Reds"</span>,</span>
<span id="cb8-297"><a href="#cb8-297" aria-hidden="true" tabindex="-1"></a>        whiskerprops<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">"black"</span>),  <span class="co"># whiskers</span></span>
<span id="cb8-298"><a href="#cb8-298" aria-hidden="true" tabindex="-1"></a>        capprops<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">"black"</span>),  <span class="co"># caps</span></span>
<span id="cb8-299"><a href="#cb8-299" aria-hidden="true" tabindex="-1"></a>        medianprops<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">"black"</span>)  <span class="co"># median line</span></span>
<span id="cb8-300"><a href="#cb8-300" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-301"><a href="#cb8-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-302"><a href="#cb8-302" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Dominant Character Type"</span>)</span>
<span id="cb8-303"><a href="#cb8-303" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"OCR Confidence"</span>)</span>
<span id="cb8-304"><a href="#cb8-304" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.title("Box Plot: OCR Confidence vs. Japanese Character Type")</span></span>
<span id="cb8-305"><a href="#cb8-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-306"><a href="#cb8-306" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb8-307"><a href="#cb8-307" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-308"><a href="#cb8-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-309"><a href="#cb8-309" aria-hidden="true" tabindex="-1"></a>The above visualization of figure 1.2 shows a box plot that shows the relationship between OCR confidence and the three types of Japanese writing systems. The graphics shows that model confidence for hiragana dominant Japanese words is higher than for katakana and kanji dominant Japanese words. This result explains that more complicated letters such as katakana and kanji are more difficult for the OCR model to process and extract compared to simpler hiragana letters.</span>
<span id="cb8-310"><a href="#cb8-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-311"><a href="#cb8-311" aria-hidden="true" tabindex="-1"></a><span class="fu">## Combined Insights</span></span>
<span id="cb8-312"><a href="#cb8-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-315"><a href="#cb8-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-316"><a href="#cb8-316" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Q1-heat</span></span>
<span id="cb8-317"><a href="#cb8-317" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 1.3: Heatmap showing correlation of word characteristics."</span></span>
<span id="cb8-318"><a href="#cb8-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-319"><a href="#cb8-319" aria-hidden="true" tabindex="-1"></a><span class="co"># use only relevant numerical columns</span></span>
<span id="cb8-320"><a href="#cb8-320" aria-hidden="true" tabindex="-1"></a>correlation_data <span class="op">=</span> df_filtered[[<span class="st">"confidence"</span>, <span class="st">"length"</span>, <span class="st">"hiragana_ratio"</span>, <span class="st">"katakana_ratio"</span>, <span class="st">"kanji_ratio"</span>]]</span>
<span id="cb8-321"><a href="#cb8-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-322"><a href="#cb8-322" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation matrix</span></span>
<span id="cb8-323"><a href="#cb8-323" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> correlation_data.corr()</span>
<span id="cb8-324"><a href="#cb8-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-325"><a href="#cb8-325" aria-hidden="true" tabindex="-1"></a><span class="co"># question 1 plot 3: heatmap</span></span>
<span id="cb8-326"><a href="#cb8-326" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb8-327"><a href="#cb8-327" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb8-328"><a href="#cb8-328" aria-hidden="true" tabindex="-1"></a>    corr_matrix, </span>
<span id="cb8-329"><a href="#cb8-329" aria-hidden="true" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,  <span class="co"># show correlation values</span></span>
<span id="cb8-330"><a href="#cb8-330" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"Reds"</span>, </span>
<span id="cb8-331"><a href="#cb8-331" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">".2f"</span>,  <span class="co"># format numbers to 2 decimal places</span></span>
<span id="cb8-332"><a href="#cb8-332" aria-hidden="true" tabindex="-1"></a>    linewidths<span class="op">=</span><span class="fl">0.5</span>,  <span class="co"># add lines between cells for clarity</span></span>
<span id="cb8-333"><a href="#cb8-333" aria-hidden="true" tabindex="-1"></a>    vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>  <span class="co"># ensure consistent color scaling</span></span>
<span id="cb8-334"><a href="#cb8-334" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-335"><a href="#cb8-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-336"><a href="#cb8-336" aria-hidden="true" tabindex="-1"></a><span class="co"># tilt x axis names</span></span>
<span id="cb8-337"><a href="#cb8-337" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">"right"</span>, rotation_mode<span class="op">=</span><span class="st">"anchor"</span>, x<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-338"><a href="#cb8-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-339"><a href="#cb8-339" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.title("Heatmap: Correlation of Word Characteristics")</span></span>
<span id="cb8-340"><a href="#cb8-340" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-341"><a href="#cb8-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-342"><a href="#cb8-342" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-343"><a href="#cb8-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-344"><a href="#cb8-344" aria-hidden="true" tabindex="-1"></a>The figure 1.3 above is a heatmap that summarizes the findings of the previous two visualizations (figure 1.1 and figure 1.2). It shows the relationships between the features of OCR confidence, word length, the ratio of hiragana in a Japanese word, the ratio of katakana in a Japanese word, and the ratio of kanji in a Japanese word. From the graph, it is clear that an OCR model's confidence score correlates positively with word length and hiragana ratio in a word, meaning that as a word's length increases and/or hiragana ratio increases, then the confidence by which it was extracted with also increases. On the other hand, an OCR model's confidence score correlates negatively with katakana ratio and kanji ratio of Japanese words, meaning that as the katakana ratio and/or kanji ratio of characters in a Japanese word increases, then the confidence by which this word was extracted by the model decreases. This result explains that the OCR model poorly performs on words with complex letters rather than longer words.</span>
<span id="cb8-345"><a href="#cb8-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-346"><a href="#cb8-346" aria-hidden="true" tabindex="-1"></a><span class="fu"># Language Characteristics and Story Telling</span></span>
<span id="cb8-347"><a href="#cb8-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-348"><a href="#cb8-348" aria-hidden="true" tabindex="-1"></a>To better understand the use of language in Grappler Baki, I continued my analysis on the grammatical and linguistic characteristics of words in the manga work. To simplify I performed analysis to see what information I can find regarding the frequency of used words, parts of speech, and in general the importance of word usage. This side of my project also delves more into understanding the themes present in *Grappler Baki*.</span>
<span id="cb8-349"><a href="#cb8-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-350"><a href="#cb8-350" aria-hidden="true" tabindex="-1"></a><span class="fu">## Word Frequency Snapshot</span></span>
<span id="cb8-351"><a href="#cb8-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-354"><a href="#cb8-354" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-355"><a href="#cb8-355" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Q2-bar1</span></span>
<span id="cb8-356"><a href="#cb8-356" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 2.1: Bar graph showing top 50 most frequent nouns across three Baki manga series."</span></span>
<span id="cb8-357"><a href="#cb8-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-358"><a href="#cb8-358" aria-hidden="true" tabindex="-1"></a><span class="co"># list of useless words to filter out</span></span>
<span id="cb8-359"><a href="#cb8-359" aria-hidden="true" tabindex="-1"></a>stopwords <span class="op">=</span> {</span>
<span id="cb8-360"><a href="#cb8-360" aria-hidden="true" tabindex="-1"></a>    <span class="st">"the"</span>, <span class="st">"a"</span>, <span class="st">"an"</span>, <span class="st">"and"</span>, <span class="st">"or"</span>, <span class="st">"but"</span>, <span class="st">"if"</span>, <span class="st">"so"</span>, <span class="st">"because"</span>,</span>
<span id="cb8-361"><a href="#cb8-361" aria-hidden="true" tabindex="-1"></a>    <span class="st">"in"</span>, <span class="st">"on"</span>, <span class="st">"at"</span>, <span class="st">"to"</span>, <span class="st">"from"</span>, <span class="st">"with"</span>, <span class="st">"by"</span>, <span class="st">"about"</span>, <span class="st">"of"</span>,</span>
<span id="cb8-362"><a href="#cb8-362" aria-hidden="true" tabindex="-1"></a>    <span class="st">"is"</span>, <span class="st">"are"</span>, <span class="st">"was"</span>, <span class="st">"were"</span>, <span class="st">"be"</span>, <span class="st">"being"</span>, <span class="st">"been"</span>, <span class="st">"am"</span>,</span>
<span id="cb8-363"><a href="#cb8-363" aria-hidden="true" tabindex="-1"></a>    <span class="st">"have"</span>, <span class="st">"has"</span>, <span class="st">"had"</span>, <span class="st">"do"</span>, <span class="st">"does"</span>, <span class="st">"did"</span>, <span class="st">"can"</span>, <span class="st">"could"</span>,</span>
<span id="cb8-364"><a href="#cb8-364" aria-hidden="true" tabindex="-1"></a>    <span class="st">"will"</span>, <span class="st">"would"</span>, <span class="st">"shall"</span>, <span class="st">"should"</span>, <span class="st">"must"</span>, <span class="st">"may"</span>, <span class="st">"might"</span>,</span>
<span id="cb8-365"><a href="#cb8-365" aria-hidden="true" tabindex="-1"></a>    <span class="st">"this"</span>, <span class="st">"that"</span>, <span class="st">"these"</span>, <span class="st">"those"</span>, <span class="st">"there"</span>, <span class="st">"here"</span>, <span class="st">"where"</span>,</span>
<span id="cb8-366"><a href="#cb8-366" aria-hidden="true" tabindex="-1"></a>    <span class="st">"when"</span>, <span class="st">"how"</span>, <span class="st">"say"</span>, <span class="st">"said"</span>, <span class="st">"tell"</span>, <span class="st">"told"</span>, <span class="st">"see"</span>, <span class="st">"saw"</span>,</span>
<span id="cb8-367"><a href="#cb8-367" aria-hidden="true" tabindex="-1"></a>    <span class="st">"look"</span>, <span class="st">"looked"</span>, <span class="st">"come"</span>, <span class="st">"go"</span>, <span class="st">"went"</span>, <span class="st">"take"</span>, <span class="st">"took"</span>,</span>
<span id="cb8-368"><a href="#cb8-368" aria-hidden="true" tabindex="-1"></a>    <span class="st">"make"</span>, <span class="st">"made"</span>, <span class="st">"get"</span>, <span class="st">"got"</span>, <span class="st">"know"</span>, <span class="st">"knew"</span>, <span class="st">"think"</span>,</span>
<span id="cb8-369"><a href="#cb8-369" aria-hidden="true" tabindex="-1"></a>    <span class="st">"thought"</span>, <span class="st">"want"</span>, <span class="st">"wanted"</span>, <span class="st">"like"</span>, <span class="st">"liked"</span>, <span class="st">"need"</span>,</span>
<span id="cb8-370"><a href="#cb8-370" aria-hidden="true" tabindex="-1"></a>    <span class="st">"needed"</span>, <span class="st">"use"</span>, <span class="st">"used"</span>, <span class="st">"find"</span>, <span class="st">"found"</span>, <span class="st">"give"</span>, <span class="st">"gave"</span>,</span>
<span id="cb8-371"><a href="#cb8-371" aria-hidden="true" tabindex="-1"></a>    <span class="st">"work"</span>, <span class="st">"works"</span>, <span class="st">"working"</span>, <span class="st">"try"</span>, <span class="st">"tried"</span>, <span class="st">"ask"</span>, <span class="st">"asked"</span>,</span>
<span id="cb8-372"><a href="#cb8-372" aria-hidden="true" tabindex="-1"></a>    <span class="st">"good"</span>, <span class="st">"bad"</span>, <span class="st">"better"</span>, <span class="st">"best"</span>, <span class="st">"worst"</span>, <span class="st">"big"</span>, <span class="st">"small"</span>,</span>
<span id="cb8-373"><a href="#cb8-373" aria-hidden="true" tabindex="-1"></a>    <span class="st">"little"</span>, <span class="st">"huge"</span>, <span class="st">"tiny"</span>, <span class="st">"old"</span>, <span class="st">"new"</span>, <span class="st">"young"</span>, <span class="st">"great"</span>,</span>
<span id="cb8-374"><a href="#cb8-374" aria-hidden="true" tabindex="-1"></a>    <span class="st">"nice"</span>, <span class="st">"mean"</span>, <span class="st">"strong"</span>, <span class="st">"weak"</span>, <span class="st">"happy"</span>, <span class="st">"sad"</span>,</span>
<span id="cb8-375"><a href="#cb8-375" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I"</span>, <span class="st">"me"</span>, <span class="st">"my"</span>, <span class="st">"mine"</span>, <span class="st">"you"</span>, <span class="st">"your"</span>, <span class="st">"yours"</span>,</span>
<span id="cb8-376"><a href="#cb8-376" aria-hidden="true" tabindex="-1"></a>    <span class="st">"he"</span>, <span class="st">"him"</span>, <span class="st">"his"</span>, <span class="st">"she"</span>, <span class="st">"her"</span>, <span class="st">"hers"</span>, <span class="st">"it"</span>, <span class="st">"its"</span>,</span>
<span id="cb8-377"><a href="#cb8-377" aria-hidden="true" tabindex="-1"></a>    <span class="st">"we"</span>, <span class="st">"us"</span>, <span class="st">"our"</span>, <span class="st">"ours"</span>, <span class="st">"they"</span>, <span class="st">"them"</span>, <span class="st">"their"</span>, <span class="st">"theirs"</span>,</span>
<span id="cb8-378"><a href="#cb8-378" aria-hidden="true" tabindex="-1"></a>    <span class="st">"yes"</span>, <span class="st">"no"</span>, <span class="st">"maybe"</span>, <span class="st">"okay"</span>, <span class="st">"really"</span>, <span class="st">"very"</span>, <span class="st">"just"</span>, <span class="st">"even"</span>, <span class="st">"still"</span>, <span class="st">"yet"</span>,</span>
<span id="cb8-379"><a href="#cb8-379" aria-hidden="true" tabindex="-1"></a>    <span class="st">"oh"</span>, <span class="st">"uh"</span>, <span class="st">"um"</span>, <span class="st">"hmm"</span>, <span class="st">"ah"</span>, <span class="st">"haha"</span>, <span class="st">"lol"</span>, <span class="st">"hmm"</span>, <span class="st">"what"</span>,</span>
<span id="cb8-380"><a href="#cb8-380" aria-hidden="true" tabindex="-1"></a>    <span class="st">"it"</span>, <span class="st">"the"</span>, <span class="st">"not"</span>, <span class="st">"is"</span>, <span class="st">"no"</span>, <span class="st">"of"</span></span>
<span id="cb8-381"><a href="#cb8-381" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-382"><a href="#cb8-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-383"><a href="#cb8-383" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------------------------------</span></span>
<span id="cb8-384"><a href="#cb8-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-385"><a href="#cb8-385" aria-hidden="true" tabindex="-1"></a><span class="co"># hide warnings for readability</span></span>
<span id="cb8-386"><a href="#cb8-386" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb8-387"><a href="#cb8-387" aria-hidden="true" tabindex="-1"></a>    warnings.simplefilter(<span class="st">"ignore"</span>)</span>
<span id="cb8-388"><a href="#cb8-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-389"><a href="#cb8-389" aria-hidden="true" tabindex="-1"></a>    <span class="co"># custom red color range </span></span>
<span id="cb8-390"><a href="#cb8-390" aria-hidden="true" tabindex="-1"></a>    custom_reds <span class="op">=</span> [<span class="st">"#ffa07a"</span>, <span class="st">"#ff4c4c"</span>, <span class="st">"#d60000"</span>, <span class="st">"#a00000"</span>, <span class="st">"#600000"</span>]</span>
<span id="cb8-391"><a href="#cb8-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-392"><a href="#cb8-392" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter for nouns only</span></span>
<span id="cb8-393"><a href="#cb8-393" aria-hidden="true" tabindex="-1"></a>    df_word_freq1 <span class="op">=</span> df[df[<span class="st">"word_POS"</span>] <span class="op">==</span> <span class="st">"noun"</span>]</span>
<span id="cb8-394"><a href="#cb8-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-395"><a href="#cb8-395" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove words with spaces or numbers</span></span>
<span id="cb8-396"><a href="#cb8-396" aria-hidden="true" tabindex="-1"></a>    df_word_freq1 <span class="op">=</span> df_word_freq1[<span class="op">~</span>df_word_freq1[<span class="st">"word_US"</span>].<span class="bu">str</span>.contains(<span class="vs">r"\s|\d"</span>, na<span class="op">=</span><span class="va">False</span>, regex<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb8-397"><a href="#cb8-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-398"><a href="#cb8-398" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter out not significant words</span></span>
<span id="cb8-399"><a href="#cb8-399" aria-hidden="true" tabindex="-1"></a>    df_word_freq1 <span class="op">=</span> df_word_freq1[<span class="op">~</span>df_word_freq1[<span class="st">"word_US"</span>].isin(stopwords)]</span>
<span id="cb8-400"><a href="#cb8-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-401"><a href="#cb8-401" aria-hidden="true" tabindex="-1"></a>    <span class="co"># total occurrences of words per series</span></span>
<span id="cb8-402"><a href="#cb8-402" aria-hidden="true" tabindex="-1"></a>    word_counts <span class="op">=</span> df_word_freq1.groupby([<span class="st">"img_series"</span>, <span class="st">"word_US"</span>])[<span class="st">"word_US"</span>].count().reset_index(name<span class="op">=</span><span class="st">"word_count"</span>)</span>
<span id="cb8-403"><a href="#cb8-403" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sort by frequency for each series (top 50)</span></span>
<span id="cb8-404"><a href="#cb8-404" aria-hidden="true" tabindex="-1"></a>    top_n <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb8-405"><a href="#cb8-405" aria-hidden="true" tabindex="-1"></a>    word_counts_top <span class="op">=</span> word_counts.sort_values(by<span class="op">=</span><span class="st">"word_count"</span>, ascending<span class="op">=</span><span class="va">False</span>).groupby(<span class="st">"img_series"</span>).head(top_n)</span>
<span id="cb8-406"><a href="#cb8-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-407"><a href="#cb8-407" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get global min and max</span></span>
<span id="cb8-408"><a href="#cb8-408" aria-hidden="true" tabindex="-1"></a>    global_min <span class="op">=</span> word_counts_top[<span class="st">"word_count"</span>].<span class="bu">min</span>()</span>
<span id="cb8-409"><a href="#cb8-409" aria-hidden="true" tabindex="-1"></a>    global_max <span class="op">=</span> word_counts_top[<span class="st">"word_count"</span>].<span class="bu">max</span>()</span>
<span id="cb8-410"><a href="#cb8-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-411"><a href="#cb8-411" aria-hidden="true" tabindex="-1"></a>    <span class="co"># function to map word count to the custom red color range</span></span>
<span id="cb8-412"><a href="#cb8-412" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> map_to_custom_reds(value, vmin, vmax):</span>
<span id="cb8-413"><a href="#cb8-413" aria-hidden="true" tabindex="-1"></a>        norm_value <span class="op">=</span> (value <span class="op">-</span> vmin) <span class="op">/</span> (vmax <span class="op">-</span> vmin)</span>
<span id="cb8-414"><a href="#cb8-414" aria-hidden="true" tabindex="-1"></a>        color_index <span class="op">=</span> <span class="bu">int</span>(norm_value <span class="op">*</span> (<span class="bu">len</span>(custom_reds) <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb8-415"><a href="#cb8-415" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> custom_reds[color_index]</span>
<span id="cb8-416"><a href="#cb8-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-417"><a href="#cb8-417" aria-hidden="true" tabindex="-1"></a>    <span class="co"># question 2 plot 1: bar graphs</span></span>
<span id="cb8-418"><a href="#cb8-418" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">11</span>))</span>
<span id="cb8-419"><a href="#cb8-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-420"><a href="#cb8-420" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over each series and create individual bar plots</span></span>
<span id="cb8-421"><a href="#cb8-421" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, series <span class="kw">in</span> <span class="bu">enumerate</span>(word_counts_top[<span class="st">'img_series'</span>].unique()):</span>
<span id="cb8-422"><a href="#cb8-422" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> axes[idx]</span>
<span id="cb8-423"><a href="#cb8-423" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> word_counts_top[word_counts_top[<span class="st">"img_series"</span>] <span class="op">==</span> series]</span>
<span id="cb8-424"><a href="#cb8-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-425"><a href="#cb8-425" aria-hidden="true" tabindex="-1"></a>        max_value <span class="op">=</span> data[<span class="st">"word_count"</span>].<span class="bu">max</span>()</span>
<span id="cb8-426"><a href="#cb8-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-427"><a href="#cb8-427" aria-hidden="true" tabindex="-1"></a>        bar_colors <span class="op">=</span> [map_to_custom_reds(value, global_min, global_max) <span class="cf">for</span> value <span class="kw">in</span> data[<span class="st">"word_count"</span>]]</span>
<span id="cb8-428"><a href="#cb8-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-429"><a href="#cb8-429" aria-hidden="true" tabindex="-1"></a>        bars <span class="op">=</span> sns.barplot(</span>
<span id="cb8-430"><a href="#cb8-430" aria-hidden="true" tabindex="-1"></a>            x<span class="op">=</span><span class="st">"word_count"</span>, </span>
<span id="cb8-431"><a href="#cb8-431" aria-hidden="true" tabindex="-1"></a>            y<span class="op">=</span><span class="st">"word_US"</span>, </span>
<span id="cb8-432"><a href="#cb8-432" aria-hidden="true" tabindex="-1"></a>            data<span class="op">=</span>data, </span>
<span id="cb8-433"><a href="#cb8-433" aria-hidden="true" tabindex="-1"></a>            ax<span class="op">=</span>ax,</span>
<span id="cb8-434"><a href="#cb8-434" aria-hidden="true" tabindex="-1"></a>            palette<span class="op">=</span>bar_colors</span>
<span id="cb8-435"><a href="#cb8-435" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-436"><a href="#cb8-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-437"><a href="#cb8-437" aria-hidden="true" tabindex="-1"></a>        <span class="co"># black edge color of bars</span></span>
<span id="cb8-438"><a href="#cb8-438" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> bar <span class="kw">in</span> bars.patches:</span>
<span id="cb8-439"><a href="#cb8-439" aria-hidden="true" tabindex="-1"></a>            bar.set_edgecolor(<span class="st">"black"</span>)</span>
<span id="cb8-440"><a href="#cb8-440" aria-hidden="true" tabindex="-1"></a>            bar.set_linewidth(<span class="dv">1</span>)</span>
<span id="cb8-441"><a href="#cb8-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-442"><a href="#cb8-442" aria-hidden="true" tabindex="-1"></a>        <span class="co"># word frquency inside each bar</span></span>
<span id="cb8-443"><a href="#cb8-443" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, value <span class="kw">in</span> <span class="bu">enumerate</span>(data[<span class="st">"word_count"</span>]):</span>
<span id="cb8-444"><a href="#cb8-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-445"><a href="#cb8-445" aria-hidden="true" tabindex="-1"></a>            text_color <span class="op">=</span> <span class="st">"white"</span> <span class="cf">if</span> series <span class="op">==</span> <span class="st">"Baki Dou 2"</span> <span class="kw">and</span> value <span class="op">==</span> max_value <span class="cf">else</span> <span class="st">"black"</span></span>
<span id="cb8-446"><a href="#cb8-446" aria-hidden="true" tabindex="-1"></a>            ax.text(value <span class="op">/</span> <span class="dv">2</span>, i, <span class="bu">str</span>(value), ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span>text_color, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb8-447"><a href="#cb8-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-448"><a href="#cb8-448" aria-hidden="true" tabindex="-1"></a>        <span class="co"># titling</span></span>
<span id="cb8-449"><a href="#cb8-449" aria-hidden="true" tabindex="-1"></a>        adjusted_series <span class="op">=</span> series.replace(<span class="st">"Hanma_Baki"</span>, <span class="st">"Hanma Baki"</span>)</span>
<span id="cb8-450"><a href="#cb8-450" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>adjusted_series<span class="sc">}</span><span class="ss"> Series"</span></span>
<span id="cb8-451"><a href="#cb8-451" aria-hidden="true" tabindex="-1"></a>        ax.set_title(title, fontweight<span class="op">=</span><span class="st">'normal'</span>)</span>
<span id="cb8-452"><a href="#cb8-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-453"><a href="#cb8-453" aria-hidden="true" tabindex="-1"></a>        <span class="co"># y-axis</span></span>
<span id="cb8-454"><a href="#cb8-454" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-455"><a href="#cb8-455" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-456"><a href="#cb8-456" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-457"><a href="#cb8-457" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-458"><a href="#cb8-458" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb8-459"><a href="#cb8-459" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-460"><a href="#cb8-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-461"><a href="#cb8-461" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x-axis</span></span>
<span id="cb8-462"><a href="#cb8-462" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-463"><a href="#cb8-463" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"Word Frequency"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-464"><a href="#cb8-464" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-465"><a href="#cb8-465" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"Word Frequency"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-466"><a href="#cb8-466" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb8-467"><a href="#cb8-467" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"Word Frequency"</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-468"><a href="#cb8-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-469"><a href="#cb8-469" aria-hidden="true" tabindex="-1"></a>        <span class="co"># remove y-axis labels</span></span>
<span id="cb8-470"><a href="#cb8-470" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-471"><a href="#cb8-471" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb8-472"><a href="#cb8-472" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb8-473"><a href="#cb8-473" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb8-474"><a href="#cb8-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-475"><a href="#cb8-475" aria-hidden="true" tabindex="-1"></a>        ax.set_xlim(<span class="dv">0</span>, data[<span class="st">"word_count"</span>].<span class="bu">max</span>())</span>
<span id="cb8-476"><a href="#cb8-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-477"><a href="#cb8-477" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb8-478"><a href="#cb8-478" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb8-479"><a href="#cb8-479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-480"><a href="#cb8-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-481"><a href="#cb8-481" aria-hidden="true" tabindex="-1"></a>To better understand the impact of themes on the story of Baki, I decided to visualize the most common nouns present across all three manga series in the form of a combined bar graph. I began by cleaning my dataset to get a fair result of my visualization. The three main tasks of this are shown below:</span>
<span id="cb8-482"><a href="#cb8-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-483"><a href="#cb8-483" aria-hidden="true" tabindex="-1"></a>**Stopword Removal:** I removed the dataset of "stopwords". An example of a common stopword is "the" or "be". They are called this because they "stop" or are excluded in almost all natural language processing. They provide no significant meaning and appear very frequently, potentially swaying the results of word analysis if they are not filtered out. In the beginning of the code section above, I show a large list of common stopwords I excluded from my dataset for this graph.</span>
<span id="cb8-484"><a href="#cb8-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-485"><a href="#cb8-485" aria-hidden="true" tabindex="-1"></a>**Additional Cleaning:** I continued by filtering my dataframe to only include nouns, since these will provide me with the most amount of context and meaninful information to understand the themes of the manga work. I also removed words with spacing or numbers, as these can cause issues for proper visualization.</span>
<span id="cb8-486"><a href="#cb8-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-487"><a href="#cb8-487" aria-hidden="true" tabindex="-1"></a>After performing the above cleaning, I put together my combined bar graphic of figure 2.1 above showning the 50 most common nouns in each manga series of Baki Dou 2, Baki Rahen, and Hanma Baki (graphs follow same order of left to right). For easier readability, the graphs were all colored by a set of 5 red colors, with darker red representing more frequency of a word and lighter red representing less frequency of a word.</span>
<span id="cb8-488"><a href="#cb8-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-489"><a href="#cb8-489" aria-hidden="true" tabindex="-1"></a>The results of this graph are really interesting in that the word "Baki", the name of the main character in *Grappler Baki*, is one of the most common nouns in all three series. In addition, words such as "Sumo", "body", "fighting", "strongest", "warrior", "death", and "man" all clearly represent the themes that the story of Grappler Baki explores. This relationship shows that the manga is character-centric, as they play an important role in the Baki story.</span>
<span id="cb8-490"><a href="#cb8-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-491"><a href="#cb8-491" aria-hidden="true" tabindex="-1"></a><span class="fu">## Parts of Speech Distribution</span></span>
<span id="cb8-492"><a href="#cb8-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-495"><a href="#cb8-495" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-496"><a href="#cb8-496" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Q2-bar2</span></span>
<span id="cb8-497"><a href="#cb8-497" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 2.2: Bar graph of normalized distributions of POS across three Baki manga series."</span></span>
<span id="cb8-498"><a href="#cb8-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-499"><a href="#cb8-499" aria-hidden="true" tabindex="-1"></a><span class="co"># filter dataset &amp; remove nulls</span></span>
<span id="cb8-500"><a href="#cb8-500" aria-hidden="true" tabindex="-1"></a>df_filtered4 <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">"word_POS"</span>, <span class="st">"img_series"</span>])</span>
<span id="cb8-501"><a href="#cb8-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-502"><a href="#cb8-502" aria-hidden="true" tabindex="-1"></a><span class="co"># count occurrences of each POS per series</span></span>
<span id="cb8-503"><a href="#cb8-503" aria-hidden="true" tabindex="-1"></a>pos_counts <span class="op">=</span> df_filtered4.groupby([<span class="st">"img_series"</span>, <span class="st">"word_POS"</span>])[<span class="st">"word_POS"</span>].count().reset_index(name<span class="op">=</span><span class="st">"count"</span>)</span>
<span id="cb8-504"><a href="#cb8-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-505"><a href="#cb8-505" aria-hidden="true" tabindex="-1"></a><span class="co"># pivot table for stacked bar format</span></span>
<span id="cb8-506"><a href="#cb8-506" aria-hidden="true" tabindex="-1"></a>pos_pivot <span class="op">=</span> pos_counts.pivot(index<span class="op">=</span><span class="st">"img_series"</span>, columns<span class="op">=</span><span class="st">"word_POS"</span>, values<span class="op">=</span><span class="st">"count"</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb8-507"><a href="#cb8-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-508"><a href="#cb8-508" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate total words in each series</span></span>
<span id="cb8-509"><a href="#cb8-509" aria-hidden="true" tabindex="-1"></a>total_words_per_series <span class="op">=</span> pos_pivot.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-510"><a href="#cb8-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-511"><a href="#cb8-511" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize each part of speech count by total words in the series</span></span>
<span id="cb8-512"><a href="#cb8-512" aria-hidden="true" tabindex="-1"></a>pos_pivot_normalized <span class="op">=</span> pos_pivot.div(total_words_per_series, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-513"><a href="#cb8-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-514"><a href="#cb8-514" aria-hidden="true" tabindex="-1"></a><span class="co"># create subplots</span></span>
<span id="cb8-515"><a href="#cb8-515" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">11</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-516"><a href="#cb8-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-517"><a href="#cb8-517" aria-hidden="true" tabindex="-1"></a><span class="co"># question 2 plot 2: bar graphs</span></span>
<span id="cb8-518"><a href="#cb8-518" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, series <span class="kw">in</span> <span class="bu">enumerate</span>(pos_pivot_normalized.index):</span>
<span id="cb8-519"><a href="#cb8-519" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]</span>
<span id="cb8-520"><a href="#cb8-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-521"><a href="#cb8-521" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pos_pivot_normalized.loc[series].sort_values(ascending<span class="op">=</span><span class="va">False</span>)  <span class="co"># sort by proportion</span></span>
<span id="cb8-522"><a href="#cb8-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-523"><a href="#cb8-523" aria-hidden="true" tabindex="-1"></a>    data.plot(kind<span class="op">=</span><span class="st">"bar"</span>, stacked<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">"red"</span>, edgecolor<span class="op">=</span><span class="st">"black"</span>, linewidth<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax)</span>
<span id="cb8-524"><a href="#cb8-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-525"><a href="#cb8-525" aria-hidden="true" tabindex="-1"></a>    ax.set_xticklabels(ax.get_xticklabels(), rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb8-526"><a href="#cb8-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-527"><a href="#cb8-527" aria-hidden="true" tabindex="-1"></a>    adjusted_series <span class="op">=</span> series.replace(<span class="st">"Hanma_Baki"</span>, <span class="st">"Hanma Baki"</span>)</span>
<span id="cb8-528"><a href="#cb8-528" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f"</span><span class="sc">{</span>adjusted_series<span class="sc">}</span><span class="ss"> Series"</span>, fontweight<span class="op">=</span><span class="st">"normal"</span>)</span>
<span id="cb8-529"><a href="#cb8-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-530"><a href="#cb8-530" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"Parts of Speech"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb8-531"><a href="#cb8-531" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Proportion"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb8-532"><a href="#cb8-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-533"><a href="#cb8-533" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-534"><a href="#cb8-534" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-535"><a href="#cb8-535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-536"><a href="#cb8-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-537"><a href="#cb8-537" aria-hidden="true" tabindex="-1"></a>I continued my thematic analysis of Baki by visualizing another bar graph of figure 2.2. This one differs from figure 2.1 in that it visulizes the normalized distribution of parts of speech across the three Baki series used in my dataset. Normalized means adjusting to take into consideration of the proportion of parts of speech across series instead of just total number of occurrences.</span>
<span id="cb8-538"><a href="#cb8-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-539"><a href="#cb8-539" aria-hidden="true" tabindex="-1"></a>The result of the above figure surprised me greatly, as the distribution of parts of speech across the series is nearly identical, with nouns, unknown, and verbs dominating the total proportion. This means that the way that *Grappler Baki* is written has not changed over the past 20 years of these manga series being published. This also shows that the story of Baki hasn't changed its direction and themes and follows the same general pattern of story-telling.</span>
<span id="cb8-540"><a href="#cb8-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-541"><a href="#cb8-541" aria-hidden="true" tabindex="-1"></a><span class="fu">## TF-IDF Insights</span></span>
<span id="cb8-542"><a href="#cb8-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-545"><a href="#cb8-545" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-546"><a href="#cb8-546" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Q2-bar3</span></span>
<span id="cb8-547"><a href="#cb8-547" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Figure 2.3: Bar graph top 20 most important words across three Baki manga series."</span></span>
<span id="cb8-548"><a href="#cb8-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-549"><a href="#cb8-549" aria-hidden="true" tabindex="-1"></a><span class="co"># hide warnings for readability</span></span>
<span id="cb8-550"><a href="#cb8-550" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb8-551"><a href="#cb8-551" aria-hidden="true" tabindex="-1"></a>    warnings.simplefilter(<span class="st">"ignore"</span>)</span>
<span id="cb8-552"><a href="#cb8-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-553"><a href="#cb8-553" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert stopwords set to list</span></span>
<span id="cb8-554"><a href="#cb8-554" aria-hidden="true" tabindex="-1"></a>    stopwords_list <span class="op">=</span> <span class="bu">list</span>(stopwords)</span>
<span id="cb8-555"><a href="#cb8-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-556"><a href="#cb8-556" aria-hidden="true" tabindex="-1"></a>    <span class="co"># filter dataset &amp; remove nulls</span></span>
<span id="cb8-557"><a href="#cb8-557" aria-hidden="true" tabindex="-1"></a>    df_filtered_tfidf <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">"word_US"</span>, <span class="st">"img_series"</span>])</span>
<span id="cb8-558"><a href="#cb8-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-559"><a href="#cb8-559" aria-hidden="true" tabindex="-1"></a>    <span class="co"># only nouns</span></span>
<span id="cb8-560"><a href="#cb8-560" aria-hidden="true" tabindex="-1"></a>    df_filtered_tfidf <span class="op">=</span> df_filtered_tfidf[df_filtered_tfidf[<span class="st">"word_POS"</span>] <span class="op">==</span> <span class="st">"noun"</span>]</span>
<span id="cb8-561"><a href="#cb8-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-562"><a href="#cb8-562" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove stopwords from "word_US" column</span></span>
<span id="cb8-563"><a href="#cb8-563" aria-hidden="true" tabindex="-1"></a>    df_filtered_tfidf <span class="op">=</span> df_filtered_tfidf[<span class="op">~</span>df_filtered_tfidf[<span class="st">"word_US"</span>].isin(stopwords_list)]</span>
<span id="cb8-564"><a href="#cb8-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-565"><a href="#cb8-565" aria-hidden="true" tabindex="-1"></a>    <span class="co"># put all words into a single document per series</span></span>
<span id="cb8-566"><a href="#cb8-566" aria-hidden="true" tabindex="-1"></a>    series_documents <span class="op">=</span> df_filtered_tfidf.groupby(<span class="st">"img_series"</span>)[<span class="st">"word_US"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join(x)).reset_index()</span>
<span id="cb8-567"><a href="#cb8-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-568"><a href="#cb8-568" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TF-IDF vectorizer setup with custom stopwords</span></span>
<span id="cb8-569"><a href="#cb8-569" aria-hidden="true" tabindex="-1"></a>    vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">300</span>, stop_words<span class="op">=</span>stopwords_list)</span>
<span id="cb8-570"><a href="#cb8-570" aria-hidden="true" tabindex="-1"></a>    tfidf_matrix <span class="op">=</span> vectorizer.fit_transform(series_documents[<span class="st">"word_US"</span>])</span>
<span id="cb8-571"><a href="#cb8-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-572"><a href="#cb8-572" aria-hidden="true" tabindex="-1"></a>    <span class="co"># matrix to dataFrame</span></span>
<span id="cb8-573"><a href="#cb8-573" aria-hidden="true" tabindex="-1"></a>    tfidf_df <span class="op">=</span> pd.DataFrame(tfidf_matrix.toarray(), index<span class="op">=</span>series_documents[<span class="st">"img_series"</span>], columns<span class="op">=</span>vectorizer.get_feature_names_out())</span>
<span id="cb8-574"><a href="#cb8-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-575"><a href="#cb8-575" aria-hidden="true" tabindex="-1"></a>    <span class="co"># top 20 highest TF-IDF words per series</span></span>
<span id="cb8-576"><a href="#cb8-576" aria-hidden="true" tabindex="-1"></a>    top_n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb8-577"><a href="#cb8-577" aria-hidden="true" tabindex="-1"></a>    top_words_per_series <span class="op">=</span> {}</span>
<span id="cb8-578"><a href="#cb8-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-579"><a href="#cb8-579" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> series <span class="kw">in</span> tfidf_df.index:</span>
<span id="cb8-580"><a href="#cb8-580" aria-hidden="true" tabindex="-1"></a>        top_words <span class="op">=</span> tfidf_df.loc[series].nlargest(top_n)</span>
<span id="cb8-581"><a href="#cb8-581" aria-hidden="true" tabindex="-1"></a>        top_words_per_series[series] <span class="op">=</span> top_words</span>
<span id="cb8-582"><a href="#cb8-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-583"><a href="#cb8-583" aria-hidden="true" tabindex="-1"></a>    <span class="co"># colors</span></span>
<span id="cb8-584"><a href="#cb8-584" aria-hidden="true" tabindex="-1"></a>    cmap <span class="op">=</span> plt.cm.Reds</span>
<span id="cb8-585"><a href="#cb8-585" aria-hidden="true" tabindex="-1"></a>    norm <span class="op">=</span> mcolors.Normalize(vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Normalize between 0 and 1 for the color map</span></span>
<span id="cb8-586"><a href="#cb8-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-587"><a href="#cb8-587" aria-hidden="true" tabindex="-1"></a>    <span class="co"># question 2 plot 3: TF-IDF</span></span>
<span id="cb8-588"><a href="#cb8-588" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">11</span>))</span>
<span id="cb8-589"><a href="#cb8-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-590"><a href="#cb8-590" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (series, words) <span class="kw">in</span> <span class="bu">enumerate</span>(top_words_per_series.items()):</span>
<span id="cb8-591"><a href="#cb8-591" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> axes[idx]</span>
<span id="cb8-592"><a href="#cb8-592" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-593"><a href="#cb8-593" aria-hidden="true" tabindex="-1"></a>        <span class="co"># normalize TF-IDF values for each word to create color gradient</span></span>
<span id="cb8-594"><a href="#cb8-594" aria-hidden="true" tabindex="-1"></a>        normalized_values <span class="op">=</span> (words.values <span class="op">-</span> words.values.<span class="bu">min</span>()) <span class="op">/</span> (words.values.<span class="bu">max</span>() <span class="op">-</span> words.values.<span class="bu">min</span>())</span>
<span id="cb8-595"><a href="#cb8-595" aria-hidden="true" tabindex="-1"></a>        colors <span class="op">=</span> [cmap(norm(val)) <span class="cf">for</span> val <span class="kw">in</span> normalized_values]</span>
<span id="cb8-596"><a href="#cb8-596" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-597"><a href="#cb8-597" aria-hidden="true" tabindex="-1"></a>        sns.barplot(x<span class="op">=</span>words.values, y<span class="op">=</span>words.index, ax<span class="op">=</span>ax, palette<span class="op">=</span>colors, edgecolor<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb8-598"><a href="#cb8-598" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f"</span><span class="sc">{</span>series<span class="sc">}</span><span class="ss"> Series"</span>)</span>
<span id="cb8-599"><a href="#cb8-599" aria-hidden="true" tabindex="-1"></a>        ax.set_xlabel(<span class="st">"TF-IDF Score"</span>)</span>
<span id="cb8-600"><a href="#cb8-600" aria-hidden="true" tabindex="-1"></a>        ax.set_ylabel(<span class="st">"Word (English)"</span>)</span>
<span id="cb8-601"><a href="#cb8-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-602"><a href="#cb8-602" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x-axis label</span></span>
<span id="cb8-603"><a href="#cb8-603" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-604"><a href="#cb8-604" aria-hidden="true" tabindex="-1"></a>            ax.set_xlabel(<span class="st">"TF-IDF Score"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb8-605"><a href="#cb8-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-606"><a href="#cb8-606" aria-hidden="true" tabindex="-1"></a>        <span class="co"># y-axis label</span></span>
<span id="cb8-607"><a href="#cb8-607" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-608"><a href="#cb8-608" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">"Word (English)"</span>, fontweight<span class="op">=</span><span class="st">"bold"</span>)</span>
<span id="cb8-609"><a href="#cb8-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-610"><a href="#cb8-610" aria-hidden="true" tabindex="-1"></a>        <span class="co"># remove x-axis</span></span>
<span id="cb8-611"><a href="#cb8-611" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if idx == 0:</span></span>
<span id="cb8-612"><a href="#cb8-612" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ax.set_xlabel('')</span></span>
<span id="cb8-613"><a href="#cb8-613" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if idx == 2:</span></span>
<span id="cb8-614"><a href="#cb8-614" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ax.set_xlabel('')</span></span>
<span id="cb8-615"><a href="#cb8-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-616"><a href="#cb8-616" aria-hidden="true" tabindex="-1"></a>        <span class="co"># remove y-axis labels</span></span>
<span id="cb8-617"><a href="#cb8-617" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-618"><a href="#cb8-618" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb8-619"><a href="#cb8-619" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb8-620"><a href="#cb8-620" aria-hidden="true" tabindex="-1"></a>            ax.set_ylabel(<span class="st">''</span>)</span>
<span id="cb8-621"><a href="#cb8-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-622"><a href="#cb8-622" aria-hidden="true" tabindex="-1"></a>        <span class="co"># set x-axis ticks to intervals of 0.15</span></span>
<span id="cb8-623"><a href="#cb8-623" aria-hidden="true" tabindex="-1"></a>        ax.set_xticks([i <span class="op">*</span> <span class="fl">0.15</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">int</span>(words.values.<span class="bu">max</span>() <span class="op">//</span> <span class="fl">0.15</span>) <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb8-624"><a href="#cb8-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-625"><a href="#cb8-625" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb8-626"><a href="#cb8-626" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb8-627"><a href="#cb8-627" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-628"><a href="#cb8-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-629"><a href="#cb8-629" aria-hidden="true" tabindex="-1"></a>The final visualization of figure 2.3 shows the results of TF-IDF analysis on the dataset in a combined bar graph format. The term when written out fully reads as term frequency-inverse document frequency and this is a technique in data analysis to measure the importance of words in a given document. During this process, a certain weight is applied to each word in a given dataset, meaning "heavier" words hold more meaning while "lighter" words hold less meaning. Weight of a word decreases by how frequently it appears in the overall word list. In general TF-IDF highlights words that are distinctive rather than common.</span>
<span id="cb8-630"><a href="#cb8-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-631"><a href="#cb8-631" aria-hidden="true" tabindex="-1"></a>In the above visualization of the top 20 most important words in each Baki series, the bars are colored with a red hue that decreases in intensity depending on TF-IDF score. The graph shows a similarity to the result in figure 2.1 of the most common nouns in all three Baki manga series. Names and words relating to the themes of the Grappler Baki story are shown, representing that characters are central to the story of Baki.</span>
<span id="cb8-632"><a href="#cb8-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-633"><a href="#cb8-633" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb8-634"><a href="#cb8-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-635"><a href="#cb8-635" aria-hidden="true" tabindex="-1"></a>The *Grappler Baki* manga maintains a consistent narrative style, with language reinforcing themes of strength and growth. OCR analysis reveals that writing style complexity negatively affects text extraction accuracy. This project shows how OCR bridges the gap in understanding manga, highlighting the value of combining technology with storytelling.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>